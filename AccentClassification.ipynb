{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from pydub import AudioSegment, silence\n",
    "from pydub.silence import split_on_silence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "              \n",
    "        self.mfccs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(os.listdir(self.root_dir))):\n",
    "\n",
    "            f = os.listdir(self.root_dir)[i]\n",
    "            with open(self.root_dir / f, 'rb') as handle:\n",
    "                entry = pickle.load(handle)\n",
    "            self.mfccs.append(entry['data'])\n",
    "            self.labels.extend(entry['labels'])\n",
    "        \n",
    "        self.mfccs = torch.from_numpy(np.vstack(self.mfccs).reshape(-1,3,50,44)).float()\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.mfccs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.mfccs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(df, files, accents, sizes):\n",
    "    for accent in accents:\n",
    "        if accent == 'us':\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        accent_df = df[df['accent'] == accent]\n",
    "        filenames = accent_df['filename'].tolist()\n",
    "        if accent in sizes:\n",
    "            filenames = filenames[:sizes[accent]]\n",
    "        for name in filenames:\n",
    "            files.append((name,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 12166\n",
      "Number of test files: 287\n"
     ]
    }
   ],
   "source": [
    "#Data setup for kaggle common voice dataset\n",
    "\n",
    "train_dir =  Path('C:/Users/omar_/Documents/cockatoos/data/train')\n",
    "test_dir =  Path('C:/Users/omar_/Documents/cockatoos/data/test')\n",
    "\n",
    "data_train_src =  Path('C:/Users/omar_/Documents/kaggle_voice/archive (1)/cv-valid-train')\n",
    "data_test_src =  Path('C:/Users/omar_/Documents/kaggle_voice/archive (1)/cv-valid-test')\n",
    "\n",
    "train_csv = Path('C:/Users/omar_/Documents/kaggle_voice/archive (1)/cv-valid-train.csv')\n",
    "test_csv = Path('C:/Users/omar_/Documents/kaggle_voice/archive (1)/cv-valid-test.csv')\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "\n",
    "accents = ['malaysia', 'african', 'wales', 'philippines','hongkong','singapore', 'indian', 'us']\n",
    "train_sizes = {'us': 6000, 'indian': 4000}\n",
    "generate_dataset(train_df, train_files, accents, train_sizes)\n",
    "test_sizes = {'us': 150}\n",
    "generate_dataset(test_df, test_files, accents, test_sizes)\n",
    "\n",
    "        \n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def generate_mfcc_data(mfcc):\n",
    "        mfcc_standardized = np.zeros(mfcc.shape)\n",
    "        for b in range(mfcc.shape[0]):\n",
    "            mfcc_slice = mfcc[b,:]\n",
    "            centered = mfcc_slice - np.mean(mfcc_slice)\n",
    "            if np.std(centered) != 0:\n",
    "                centered_scaled = centered / np.std(centered)\n",
    "\n",
    "            mfcc_standardized[b,:] = centered_scaled\n",
    "\n",
    "        delta1 = librosa.feature.delta(mfcc_standardized, order=1)\n",
    "        delta2 = librosa.feature.delta(mfcc_standardized, order=2)\n",
    "        mfcc_data = np.stack((mfcc_standardized,delta1,delta2))\n",
    "        \n",
    "        return mfcc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_standardize_audio(path, seg_size):\n",
    "    sound_file = AudioSegment.from_mp3(path)\n",
    "    limit = len(sound_file) // seg_size if len(sound_file) % seg_size == 0 else len(sound_file) // seg_size + 1\n",
    "    chunks = []\n",
    "    for i in range(0,limit):\n",
    "        chunk = sound_file[i * seg_size : (i + 1) * seg_size]\n",
    "        if len(chunk) < seg_size:\n",
    "            chunk = chunk + AudioSegment.silent(duration=(seg_size - len(chunk)))\n",
    "          \n",
    "\n",
    "        if np.count_nonzero(chunk.get_array_of_samples()) > 45000:\n",
    "            chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_data(src, dst, files, train, mean=0, std=1):\n",
    "    \n",
    "    counter = 0\n",
    "    seg_size = 1000\n",
    "    batch_num = 1\n",
    "    mfccs = []\n",
    "    items = []\n",
    "    labels = []\n",
    "    n_mfcc = 50\n",
    "    mfcc_width = 44\n",
    "    c = 0\n",
    "    \n",
    "    for f in files:\n",
    "\n",
    "     \n",
    "        # use for common voice data\n",
    "        label = f[1]\n",
    "        audio_chunks = segment_and_standardize_audio(src / f[0], seg_size)\n",
    "        for seg in audio_chunks:\n",
    "                 \n",
    "            samples = seg.get_array_of_samples()\n",
    "            arr = np.array(samples).astype(np.float32)/32768 # 16 bit \n",
    "            arr = librosa.core.resample(arr, seg.frame_rate, 22050, res_type='kaiser_best') \n",
    "                \n",
    "            mfcc = librosa.feature.mfcc(y=arr, sr=22050, n_mfcc=n_mfcc)\n",
    "            mfccs.append(mfcc)\n",
    "            labels.append(label)\n",
    "            \n",
    "        c += 1\n",
    "        if c % 100 == 0:\n",
    "            print(f\"Processed {c} files\")\n",
    "        \n",
    "        \n",
    "    all_data = np.vstack(mfccs).reshape(-1,n_mfcc,mfcc_width)\n",
    "    if train:\n",
    "        mean = all_data.mean(axis=0)\n",
    "        std = all_data.std(axis=0)\n",
    "        all_data = (all_data - mean) / std\n",
    "    else:\n",
    "        all_data = (all_data - mean) / std\n",
    "    \n",
    "    for j in range(all_data.shape[0]):\n",
    "        d = generate_mfcc_data(all_data[j])\n",
    "        items.append(d)\n",
    "    \n",
    "    \n",
    "    batch_size = len(labels) // 6\n",
    "    for j in range(6):\n",
    "        \n",
    "        start = j * batch_size\n",
    "        end = start + batch_size\n",
    "        if j == 5 and len(labels) % 6 != 0:\n",
    "            end = len(labels)\n",
    "        curr_data = items[start:end]\n",
    "        curr_labels = labels[start:end]\n",
    "        batch_mfcc = np.vstack(curr_data).reshape(-1,3,n_mfcc,mfcc_width)\n",
    "        entry = dict()\n",
    "        entry['data'] = batch_mfcc\n",
    "        entry['labels'] = curr_labels\n",
    "        with open(dst / f'data_batch_{j+1}.pickle', 'wb') as handle:\n",
    "            pickle.dump(entry, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "        \n",
    "    if train:\n",
    "        return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 files\n",
      "Processed 200 files\n",
      "Testing words created\n"
     ]
    }
   ],
   "source": [
    "#Uncomment to create the files for the dataset folders (common voice)\n",
    "\n",
    "# mean, std = generate_model_data(data_train_src, train_dir, train_files, True)\n",
    "# print(\"Training words created\")\n",
    "# generate_model_data(data_test_src, test_dir, test_files, False, mean, std)\n",
    "# print(\"Testing words created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = Path('C:/Users/omar_/Documents/cockatoos/data/train')\n",
    "test_data_dir = Path('C:/Users/omar_/Documents/cockatoos/data/test')\n",
    "\n",
    "train_data = MFCCDataset(train_data_dir)\n",
    "test_data = MFCCDataset(test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten(1,3),\n",
    "            nn.Linear(6336,256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  Loss: 0.9169487223932238  Accuracy: 57.13608345187293\n",
      "Epoch 2  Loss: 0.6490876372113372  Accuracy: 61.5398293029872\n",
      "Epoch 3  Loss: 0.6421443113323414  Accuracy: 62.39331436699858\n",
      "Epoch 4  Loss: 0.6372921959017263  Accuracy: 62.84376481744903\n",
      "Epoch 5  Loss: 0.6286762456099192  Accuracy: 64.07657657657657\n",
      "Epoch 6  Loss: 0.6228202922326146  Accuracy: 64.48850165955429\n",
      "Epoch 7  Loss: 0.6192113021106431  Accuracy: 65.1967757230915\n",
      "Epoch 8  Loss: 0.6126357872377742  Accuracy: 65.98210052157421\n",
      "Epoch 9  Loss: 0.604826879772273  Accuracy: 66.93930772878142\n",
      "Epoch 10  Loss: 0.5992452933481245  Accuracy: 66.77631578947368\n",
      "Epoch 11  Loss: 0.5914975576328508  Accuracy: 67.7898293029872\n",
      "Epoch 12  Loss: 0.5850246977625471  Accuracy: 68.53959222380276\n",
      "Epoch 13  Loss: 0.5760906907645139  Accuracy: 69.1678520625889\n",
      "Epoch 14  Loss: 0.5732338963584467  Accuracy: 69.36936936936937\n",
      "Epoch 15  Loss: 0.5652462466422356  Accuracy: 69.99466571834994\n",
      "Epoch 16  Loss: 0.5588383462392923  Accuracy: 70.63477951635846\n",
      "Epoch 17  Loss: 0.5524947130770395  Accuracy: 71.30749170222855\n",
      "Epoch 18  Loss: 0.549672560822783  Accuracy: 71.18895211000473\n",
      "Epoch 19  Loss: 0.5414483785403498  Accuracy: 71.86166429587482\n",
      "Epoch 20  Loss: 0.5360357703810389  Accuracy: 72.4810336652442\n",
      "Epoch 21  Loss: 0.5339372276582501  Accuracy: 72.57586533902324\n",
      "Epoch 22  Loss: 0.5286609881529303  Accuracy: 72.96408250355618\n",
      "Epoch 23  Loss: 0.5249329280446876  Accuracy: 73.32859174964437\n",
      "Epoch 24  Loss: 0.51744087243622  Accuracy: 73.71088193456615\n",
      "Epoch 25  Loss: 0.5126326238792954  Accuracy: 74.17911332385016\n",
      "Epoch 26  Loss: 0.5080321336334402  Accuracy: 74.95851114272168\n",
      "Epoch 27  Loss: 0.5070789867278301  Accuracy: 74.5199146514936\n",
      "Epoch 28  Loss: 0.5027955618094314  Accuracy: 74.7006875296349\n",
      "Epoch 29  Loss: 0.5038653595203703  Accuracy: 74.76884779516358\n",
      "Epoch 30  Loss: 0.49679944788416225  Accuracy: 75.34376481744903\n",
      "Epoch 31  Loss: 0.4940923379000389  Accuracy: 75.46823138928401\n",
      "Epoch 32  Loss: 0.4908261243818384  Accuracy: 75.63418681839734\n",
      "Epoch 33  Loss: 0.4873914307717121  Accuracy: 76.0816737790422\n",
      "Epoch 34  Loss: 0.48691789760734094  Accuracy: 76.10241820768137\n",
      "Epoch 35  Loss: 0.4817365008321675  Accuracy: 76.3187529634898\n",
      "Epoch 36  Loss: 0.48021845892071724  Accuracy: 76.49063537221431\n",
      "Epoch 37  Loss: 0.47661903150605434  Accuracy: 76.84032716927453\n",
      "Epoch 38  Loss: 0.472981705132759  Accuracy: 77.24336178283546\n",
      "Epoch 39  Loss: 0.4666042396742286  Accuracy: 77.48044096728307\n",
      "Epoch 40  Loss: 0.4657349777266835  Accuracy: 77.57823613086771\n",
      "Epoch 41  Loss: 0.4597275179218162  Accuracy: 77.87754860123282\n",
      "Epoch 42  Loss: 0.46569751914251933  Accuracy: 77.45376955903272\n",
      "Epoch 43  Loss: 0.4617895736838832  Accuracy: 77.83013276434329\n",
      "Epoch 44  Loss: 0.46314225018475996  Accuracy: 77.63157894736842\n",
      "Epoch 45  Loss: 0.45455149098327663  Accuracy: 78.2450213371266\n",
      "Epoch 46  Loss: 0.45377234719467885  Accuracy: 78.21538643907066\n",
      "Epoch 47  Loss: 0.4537650947317933  Accuracy: 78.1857515410147\n",
      "Epoch 48  Loss: 0.4503597281873226  Accuracy: 78.62138454243717\n",
      "Epoch 49  Loss: 0.4488184410288478  Accuracy: 78.55026078710289\n",
      "Epoch 50  Loss: 0.448527223684571  Accuracy: 78.71621621621621\n",
      "Epoch 51  Loss: 0.4451187328633034  Accuracy: 78.92958748221906\n",
      "Epoch 52  Loss: 0.43749658086083154  Accuracy: 79.28816974869606\n",
      "Epoch 53  Loss: 0.43823855505748227  Accuracy: 79.25260787102893\n",
      "Epoch 54  Loss: 0.43762287023392593  Accuracy: 79.3830014224751\n",
      "Epoch 55  Loss: 0.439566800765919  Accuracy: 79.22000948316737\n",
      "Epoch 56  Loss: 0.4353988729417324  Accuracy: 79.47486960644855\n",
      "Epoch 57  Loss: 0.43340955211809185  Accuracy: 79.7415836889521\n",
      "Epoch 58  Loss: 0.4292404398773656  Accuracy: 79.76529160739688\n",
      "Epoch 59  Loss: 0.4299393141585769  Accuracy: 80.03200568990043\n",
      "Epoch 60  Loss: 0.42913915047591383  Accuracy: 79.9282835467046\n",
      "Epoch 61  Loss: 0.4270751199713259  Accuracy: 79.8660502607871\n",
      "Epoch 62  Loss: 0.42449757524512033  Accuracy: 80.06460407776197\n",
      "Epoch 63  Loss: 0.42527279968966136  Accuracy: 80.15943575154101\n",
      "Epoch 64  Loss: 0.422632906247269  Accuracy: 80.17425320056898\n",
      "Epoch 65  Loss: 0.4201068520320184  Accuracy: 80.31650071123755\n",
      "Epoch 66  Loss: 0.41924967684529046  Accuracy: 80.45874822190612\n",
      "Epoch 67  Loss: 0.4177495494033351  Accuracy: 80.51505452821242\n",
      "Epoch 68  Loss: 0.4169312958238703  Accuracy: 80.56247036510194\n",
      "Epoch 69  Loss: 0.4184234409847043  Accuracy: 80.47652916073969\n",
      "Epoch 70  Loss: 0.4167062659381014  Accuracy: 80.4735656709341\n",
      "Epoch 71  Loss: 0.41659933497959917  Accuracy: 80.60395922238027\n",
      "Epoch 72  Loss: 0.41505737726887065  Accuracy: 80.87067330488384\n",
      "Epoch 73  Loss: 0.41068652531865874  Accuracy: 80.90030820293978\n",
      "Epoch 74  Loss: 0.4051045800248782  Accuracy: 81.1877667140825\n",
      "Epoch 75  Loss: 0.40896661489298847  Accuracy: 80.92994310099573\n",
      "Epoch 76  Loss: 0.4120710224590518  Accuracy: 80.77880512091038\n",
      "Epoch 77  Loss: 0.4089706431735646  Accuracy: 80.96550497866288\n",
      "Epoch 78  Loss: 0.40787073348959285  Accuracy: 81.05440967283073\n",
      "Epoch 79  Loss: 0.40017947814229765  Accuracy: 81.38928402086297\n",
      "Epoch 80  Loss: 0.40352566743438895  Accuracy: 81.5493124703651\n",
      "Epoch 81  Loss: 0.40506916335134796  Accuracy: 81.25\n",
      "Epoch 82  Loss: 0.4037150087004358  Accuracy: 81.05737316263632\n",
      "Epoch 83  Loss: 0.39813073126204085  Accuracy: 81.82195353247985\n",
      "Epoch 84  Loss: 0.3988903057620381  Accuracy: 81.75379326695116\n",
      "Epoch 85  Loss: 0.39688250874028064  Accuracy: 81.83084400189664\n",
      "Epoch 86  Loss: 0.4005044504548564  Accuracy: 81.46040777619724\n",
      "Epoch 87  Loss: 0.39906234124844725  Accuracy: 81.83677098150783\n",
      "Epoch 88  Loss: 0.398004750072053  Accuracy: 81.59969179706022\n",
      "Epoch 89  Loss: 0.3962530458176678  Accuracy: 81.9167852062589\n",
      "Epoch 90  Loss: 0.39375800718412257  Accuracy: 81.967164532954\n",
      "Epoch 91  Loss: 0.3977852795611728  Accuracy: 81.83380749170223\n",
      "Epoch 92  Loss: 0.3948588229038499  Accuracy: 82.00865339023234\n",
      "Epoch 93  Loss: 0.3928528659497247  Accuracy: 81.99976292081556\n",
      "Epoch 94  Loss: 0.38909510444059514  Accuracy: 82.23980559506876\n",
      "Epoch 95  Loss: 0.38988556532245694  Accuracy: 82.17460881934566\n",
      "Epoch 96  Loss: 0.3900781548158689  Accuracy: 82.23980559506876\n",
      "Epoch 97  Loss: 0.3838943568142978  Accuracy: 82.35538169748696\n",
      "Epoch 98  Loss: 0.39131548944296257  Accuracy: 82.04421526789947\n",
      "Epoch 99  Loss: 0.3857881048637809  Accuracy: 82.51837363679469\n",
      "Epoch 100  Loss: 0.38886581570135825  Accuracy: 82.2753674727359\n",
      "Higher validaiton accuracy score achieved! Saving model.\n",
      "Model test accuracy for fold 0: 66.8 \n",
      "Epoch 1  Loss: 11.685850885555599  Accuracy: 54.540066382171645\n",
      "Epoch 2  Loss: 0.6650906573190833  Accuracy: 59.15718349928876\n",
      "Epoch 3  Loss: 0.6583100191571496  Accuracy: 60.00177809388336\n",
      "Epoch 4  Loss: 0.656100037197272  Accuracy: 60.60633001422475\n",
      "Epoch 5  Loss: 0.6491242279157494  Accuracy: 61.55761024182077\n",
      "Epoch 6  Loss: 0.6438670946341573  Accuracy: 61.66133238501659\n",
      "Epoch 7  Loss: 0.6358955249641881  Accuracy: 63.134186818397346\n",
      "Epoch 8  Loss: 0.6269421904827609  Accuracy: 63.91062114746325\n",
      "Epoch 9  Loss: 0.6186105577331601  Accuracy: 64.8411569464201\n",
      "Epoch 10  Loss: 0.6114980253306302  Accuracy: 65.83392603129445\n",
      "Epoch 11  Loss: 0.6027177380341472  Accuracy: 66.73779042200094\n",
      "Epoch 12  Loss: 0.5946086400160284  Accuracy: 67.27418207681366\n",
      "Epoch 13  Loss: 0.5878132092907573  Accuracy: 67.92022285443338\n",
      "Epoch 14  Loss: 0.5804252139095104  Accuracy: 69.04042200094831\n",
      "Epoch 15  Loss: 0.5706152038818056  Accuracy: 69.37529634898056\n",
      "Epoch 16  Loss: 0.5698144702297269  Accuracy: 69.77833096254149\n",
      "Epoch 17  Loss: 0.5585065360999468  Accuracy: 70.41844476055002\n",
      "Epoch 18  Loss: 0.5506723987107928  Accuracy: 71.11190137505928\n",
      "Epoch 19  Loss: 0.5463478821470882  Accuracy: 71.5149359886202\n",
      "Epoch 20  Loss: 0.5400571242877932  Accuracy: 72.25284495021337\n",
      "Epoch 21  Loss: 0.5320080658703139  Accuracy: 73.0707681365576\n",
      "Epoch 22  Loss: 0.5270912305197932  Accuracy: 73.08558558558559\n",
      "Epoch 23  Loss: 0.5227917798540809  Accuracy: 73.6812470365102\n",
      "Epoch 24  Loss: 0.5172193028935881  Accuracy: 74.12280701754386\n",
      "Epoch 25  Loss: 0.5115615561830275  Accuracy: 74.38655761024182\n",
      "Epoch 26  Loss: 0.5115940634048346  Accuracy: 74.50509720246562\n",
      "Epoch 27  Loss: 0.5010193019653811  Accuracy: 75.20744428639165\n",
      "Epoch 28  Loss: 0.503280601718209  Accuracy: 74.89627785680418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29  Loss: 0.49660611976728297  Accuracy: 75.64900426742533\n",
      "Epoch 30  Loss: 0.491098141579917  Accuracy: 75.82385016595543\n",
      "Epoch 31  Loss: 0.4868248723673098  Accuracy: 76.20614035087719\n",
      "Epoch 32  Loss: 0.48685861920768564  Accuracy: 76.22688477951635\n",
      "Epoch 33  Loss: 0.48210234691699344  Accuracy: 76.48174490279753\n",
      "Epoch 34  Loss: 0.4815569393562548  Accuracy: 76.47285443338075\n",
      "Epoch 35  Loss: 0.47510363387339044  Accuracy: 77.08926031294452\n",
      "Epoch 36  Loss: 0.47319610958749597  Accuracy: 77.24039829302987\n",
      "Epoch 37  Loss: 0.4701695430910949  Accuracy: 77.21965386439071\n",
      "Epoch 38  Loss: 0.46727703590736247  Accuracy: 77.38857278330963\n",
      "Epoch 39  Loss: 0.46336072502714215  Accuracy: 77.79457088667615\n",
      "Epoch 40  Loss: 0.45699054318847077  Accuracy: 78.08795637743006\n",
      "Epoch 41  Loss: 0.458226778967814  Accuracy: 78.20353247984826\n",
      "Epoch 42  Loss: 0.4556111226027662  Accuracy: 78.15315315315316\n",
      "Epoch 43  Loss: 0.452579181980003  Accuracy: 78.26872925557136\n",
      "Epoch 44  Loss: 0.45018915583690006  Accuracy: 78.58285917496444\n",
      "Epoch 45  Loss: 0.44828112920125324  Accuracy: 78.75177809388336\n",
      "Epoch 46  Loss: 0.44364674998955295  Accuracy: 78.91477003319109\n",
      "Epoch 47  Loss: 0.443432974657326  Accuracy: 78.9058795637743\n",
      "Epoch 48  Loss: 0.4437265568836169  Accuracy: 78.8436462778568\n",
      "Epoch 49  Loss: 0.4415307207541032  Accuracy: 79.05405405405405\n",
      "Epoch 50  Loss: 0.4366686191748489  Accuracy: 79.36225699383594\n",
      "Epoch 51  Loss: 0.4352619048546661  Accuracy: 79.3889284020863\n",
      "Epoch 52  Loss: 0.43749332439267274  Accuracy: 79.18444760550024\n",
      "Epoch 53  Loss: 0.4302639216184616  Accuracy: 79.84234234234235\n",
      "Epoch 54  Loss: 0.43192685485789273  Accuracy: 79.81863442389758\n",
      "Epoch 55  Loss: 0.42678412907954416  Accuracy: 80.1683262209578\n",
      "Epoch 56  Loss: 0.42520298966855713  Accuracy: 80.02311522048365\n",
      "Epoch 57  Loss: 0.42629930106076325  Accuracy: 80.13572783309625\n",
      "Epoch 58  Loss: 0.422853300404368  Accuracy: 80.23352299668089\n",
      "Epoch 59  Loss: 0.4249030120219245  Accuracy: 80.03793266951162\n",
      "Epoch 60  Loss: 0.4195244377761176  Accuracy: 80.5298719772404\n",
      "Epoch 61  Loss: 0.41700754551724956  Accuracy: 80.57432432432432\n",
      "Epoch 62  Loss: 0.4174339020568313  Accuracy: 80.71657183499289\n",
      "Epoch 63  Loss: 0.41427067215695523  Accuracy: 80.50320056899004\n",
      "Epoch 64  Loss: 0.4121180579743602  Accuracy: 80.96550497866288\n",
      "Epoch 65  Loss: 0.4129061365895199  Accuracy: 80.82325746799431\n",
      "Epoch 66  Loss: 0.41084265392838104  Accuracy: 80.9477240398293\n",
      "Epoch 67  Loss: 0.4097471920152505  Accuracy: 80.98921289710763\n",
      "Epoch 68  Loss: 0.4098843911832029  Accuracy: 81.20258416311047\n",
      "Epoch 69  Loss: 0.4099024836764191  Accuracy: 80.9536510194405\n",
      "Epoch 70  Loss: 0.40759893890583154  Accuracy: 81.30037932669512\n",
      "Epoch 71  Loss: 0.4042614427479831  Accuracy: 81.37150308202939\n",
      "Epoch 72  Loss: 0.4027577123858712  Accuracy: 81.5522759601707\n",
      "Epoch 73  Loss: 0.4043386203773094  Accuracy: 81.47522522522523\n",
      "Epoch 74  Loss: 0.40553701849597873  Accuracy: 81.36261261261261\n",
      "Epoch 75  Loss: 0.3991914341847102  Accuracy: 81.61450924608819\n",
      "Epoch 76  Loss: 0.4008176075012395  Accuracy: 81.6678520625889\n",
      "Epoch 77  Loss: 0.39701446360259346  Accuracy: 81.7863916548127\n",
      "Epoch 78  Loss: 0.39678186866821663  Accuracy: 81.82788051209104\n",
      "Epoch 79  Loss: 0.39575254093065404  Accuracy: 81.77157420578473\n",
      "Epoch 80  Loss: 0.3936370547973748  Accuracy: 81.95234708392603\n",
      "Epoch 81  Loss: 0.39364218339324  Accuracy: 81.81899004267426\n",
      "Epoch 82  Loss: 0.3945547401001959  Accuracy: 81.99087245139877\n",
      "Epoch 83  Loss: 0.3909811789565014  Accuracy: 82.12422949265054\n",
      "Epoch 84  Loss: 0.3953994678502733  Accuracy: 81.89900426742533\n",
      "Epoch 85  Loss: 0.3927210315384648  Accuracy: 81.85751541014699\n",
      "Epoch 86  Loss: 0.387319093626557  Accuracy: 82.35241820768137\n",
      "Epoch 87  Loss: 0.3904878075488589  Accuracy: 82.41761498340446\n",
      "Epoch 88  Loss: 0.3878706445296605  Accuracy: 82.22498814604077\n",
      "Epoch 89  Loss: 0.3880668403298566  Accuracy: 82.43835941204362\n",
      "Epoch 90  Loss: 0.38715215174086165  Accuracy: 82.50948316737791\n",
      "Epoch 91  Loss: 0.38652075307838846  Accuracy: 82.52726410621148\n",
      "Epoch 92  Loss: 0.38880470412021334  Accuracy: 82.19238975817923\n",
      "Epoch 93  Loss: 0.38625129729960905  Accuracy: 82.37316263632053\n",
      "Epoch 94  Loss: 0.3812797111317967  Accuracy: 82.82954006638217\n",
      "Epoch 95  Loss: 0.3829495691214547  Accuracy: 82.79397818871503\n",
      "Epoch 96  Loss: 0.38542527253880643  Accuracy: 82.64876718824087\n",
      "Epoch 97  Loss: 0.3869228478182446  Accuracy: 82.17164532954007\n",
      "Epoch 98  Loss: 0.38281456302061223  Accuracy: 82.69914651493599\n",
      "Epoch 99  Loss: 0.38079997253688896  Accuracy: 82.63987671882408\n",
      "Epoch 100  Loss: 0.37727672279332625  Accuracy: 83.12588904694168\n",
      "Higher validaiton accuracy score achieved! Saving model.\n",
      "Model test accuracy for fold 1: 67.14666666666666 \n",
      "Epoch 1  Loss: 1.1753200748653123  Accuracy: 56.98198198198198\n",
      "Epoch 2  Loss: 0.6470681713386015  Accuracy: 61.750237079184444\n",
      "Epoch 3  Loss: 0.6407246510639335  Accuracy: 62.307373162636324\n",
      "Epoch 4  Loss: 0.6342781070958484  Accuracy: 63.14900426742532\n",
      "Epoch 5  Loss: 0.6306392767212607  Accuracy: 63.87505926979611\n",
      "Epoch 6  Loss: 0.6204054768789898  Accuracy: 64.99822190611664\n",
      "Epoch 7  Loss: 0.6151880685127142  Accuracy: 65.7450213371266\n",
      "Epoch 8  Loss: 0.6073989773338492  Accuracy: 66.40291607396871\n",
      "Epoch 9  Loss: 0.6030826824858333  Accuracy: 66.57479848269323\n",
      "Epoch 10  Loss: 0.5923236412080851  Accuracy: 67.79575628259839\n",
      "Epoch 11  Loss: 0.5861490953600768  Accuracy: 68.29065908013277\n",
      "Epoch 12  Loss: 0.5791988693403475  Accuracy: 68.81816026552869\n",
      "Epoch 13  Loss: 0.5707183754579588  Accuracy: 69.80203888098625\n",
      "Epoch 14  Loss: 0.5675067065114324  Accuracy: 69.97392128971076\n",
      "Epoch 15  Loss: 0.5610499385405671  Accuracy: 70.59921763869133\n",
      "Epoch 16  Loss: 0.5561707692615914  Accuracy: 70.78591749644382\n",
      "Epoch 17  Loss: 0.5476450556606958  Accuracy: 71.36676149834045\n",
      "Epoch 18  Loss: 0.5453854457221248  Accuracy: 71.85277382645803\n",
      "Epoch 19  Loss: 0.5413627316328612  Accuracy: 72.34767662399241\n",
      "Epoch 20  Loss: 0.5351935945677034  Accuracy: 72.77145566619251\n",
      "Epoch 21  Loss: 0.5271325579872637  Accuracy: 73.20412517780939\n",
      "Epoch 22  Loss: 0.5237866797004685  Accuracy: 73.6190137505927\n",
      "Epoch 23  Loss: 0.5197596267768831  Accuracy: 73.9123992413466\n",
      "Epoch 24  Loss: 0.5158966271714731  Accuracy: 73.82053105737316\n",
      "Epoch 25  Loss: 0.5082612297300136  Accuracy: 74.72143195827407\n",
      "Epoch 26  Loss: 0.5055615399597269  Accuracy: 74.91702228544334\n",
      "Epoch 27  Loss: 0.4994396854079131  Accuracy: 75.0622332859175\n",
      "Epoch 28  Loss: 0.4976605696208549  Accuracy: 75.52453769559033\n",
      "Epoch 29  Loss: 0.49774692659125186  Accuracy: 75.2963489805595\n",
      "Epoch 30  Loss: 0.4877165043444345  Accuracy: 76.07278330962542\n",
      "Epoch 31  Loss: 0.48731627213684  Accuracy: 76.32467994310099\n",
      "Epoch 32  Loss: 0.4829943349415606  Accuracy: 76.3809862494073\n",
      "Epoch 33  Loss: 0.48454991897398775  Accuracy: 76.27726410621148\n",
      "Epoch 34  Loss: 0.4757332434934197  Accuracy: 76.72771455666192\n",
      "Epoch 35  Loss: 0.47351593027512234  Accuracy: 76.77216690374586\n",
      "Epoch 36  Loss: 0.47229725235339365  Accuracy: 77.11889521100048\n",
      "Epoch 37  Loss: 0.46712864664467896  Accuracy: 77.22854433380749\n",
      "Epoch 38  Loss: 0.4640013278659546  Accuracy: 77.53674727358938\n",
      "Epoch 39  Loss: 0.4638283940201456  Accuracy: 77.96052631578948\n",
      "Epoch 40  Loss: 0.45829488517660083  Accuracy: 78.02868658131815\n",
      "Epoch 41  Loss: 0.4559288775604783  Accuracy: 77.99312470365102\n",
      "Epoch 42  Loss: 0.4567654367649194  Accuracy: 78.16204362256994\n",
      "Epoch 43  Loss: 0.4558500081978061  Accuracy: 77.98719772403983\n",
      "Epoch 44  Loss: 0.4478318963312741  Accuracy: 78.58878615457563\n",
      "Epoch 45  Loss: 0.446526920592243  Accuracy: 78.64509246088194\n",
      "Epoch 46  Loss: 0.4413485750555992  Accuracy: 79.18148411569464\n",
      "Epoch 47  Loss: 0.4399264765282472  Accuracy: 79.16666666666667\n",
      "Epoch 48  Loss: 0.4405426922621149  Accuracy: 79.30891417733523\n",
      "Epoch 49  Loss: 0.4347047275214484  Accuracy: 79.5637743006164\n",
      "Epoch 50  Loss: 0.43856456898378604  Accuracy: 79.36818397344713\n",
      "Epoch 51  Loss: 0.4361661068643584  Accuracy: 79.45412517780939\n",
      "Epoch 52  Loss: 0.4365499683401801  Accuracy: 79.46301564722617\n",
      "Epoch 53  Loss: 0.42824337913682964  Accuracy: 79.75047415836889\n",
      "Epoch 54  Loss: 0.4276348832204486  Accuracy: 80.00237079184447\n",
      "Epoch 55  Loss: 0.42963540892709384  Accuracy: 80.08238501659554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56  Loss: 0.421578352537119  Accuracy: 80.25130393551446\n",
      "Epoch 57  Loss: 0.4200916453970201  Accuracy: 80.45282124229493\n",
      "Epoch 58  Loss: 0.4217178052799268  Accuracy: 80.31353722143196\n",
      "Epoch 59  Loss: 0.42514178258451546  Accuracy: 80.19796111901375\n",
      "Epoch 60  Loss: 0.4209017533470284  Accuracy: 80.532835467046\n",
      "Epoch 61  Loss: 0.41740291689833003  Accuracy: 80.66026552868658\n",
      "Epoch 62  Loss: 0.4163429496640509  Accuracy: 80.5832147937411\n",
      "Epoch 63  Loss: 0.41189706201354664  Accuracy: 81.0099573257468\n",
      "Epoch 64  Loss: 0.4075225643587835  Accuracy: 81.27963489805595\n",
      "Epoch 65  Loss: 0.4135451167821884  Accuracy: 80.86770981507824\n",
      "Epoch 66  Loss: 0.4086885808995276  Accuracy: 81.25889046941678\n",
      "Epoch 67  Loss: 0.4126396237900763  Accuracy: 80.87067330488384\n",
      "Epoch 68  Loss: 0.4080764281027245  Accuracy: 81.20554765291607\n",
      "Epoch 69  Loss: 0.4020135547175552  Accuracy: 81.52264106211474\n",
      "Epoch 70  Loss: 0.40148578708370525  Accuracy: 81.45744428639165\n",
      "Epoch 71  Loss: 0.4066797601002635  Accuracy: 81.36261261261261\n",
      "Epoch 72  Loss: 0.40394558255193813  Accuracy: 81.28852536747273\n",
      "Epoch 73  Loss: 0.3994697383181615  Accuracy: 81.69748696064485\n",
      "Epoch 74  Loss: 0.3982966042151957  Accuracy: 81.74490279753438\n",
      "Epoch 75  Loss: 0.3980451686815782  Accuracy: 81.7300853485064\n",
      "Epoch 76  Loss: 0.3963316351626859  Accuracy: 81.90493124703652\n",
      "Epoch 77  Loss: 0.39765448653788277  Accuracy: 81.74193930772879\n",
      "Epoch 78  Loss: 0.39662385314251436  Accuracy: 81.85751541014699\n",
      "Epoch 79  Loss: 0.3963443720431039  Accuracy: 82.10941204362257\n",
      "Epoch 80  Loss: 0.39717874788876734  Accuracy: 81.8486249407302\n",
      "Epoch 81  Loss: 0.39290763437747955  Accuracy: 82.10052157420579\n",
      "Epoch 82  Loss: 0.3870765030609839  Accuracy: 82.37908961593172\n",
      "Epoch 83  Loss: 0.39395086591442424  Accuracy: 81.95531057373162\n",
      "Epoch 84  Loss: 0.38726857101375406  Accuracy: 82.37908961593172\n",
      "Epoch 85  Loss: 0.3861378116363829  Accuracy: 82.31685633001422\n",
      "Epoch 86  Loss: 0.3876113165734392  Accuracy: 82.18646277856804\n",
      "Epoch 87  Loss: 0.38851148115866113  Accuracy: 82.22498814604077\n",
      "Epoch 88  Loss: 0.3881680200045759  Accuracy: 82.10052157420579\n",
      "Epoch 89  Loss: 0.3855285585829706  Accuracy: 82.34056424845899\n",
      "Epoch 90  Loss: 0.3827261816371571  Accuracy: 82.62505926979611\n",
      "Epoch 91  Loss: 0.3873180237909158  Accuracy: 82.2694404931247\n",
      "Epoch 92  Loss: 0.3792140077460896  Accuracy: 82.64876718824087\n",
      "Epoch 93  Loss: 0.3803276718791687  Accuracy: 82.63691322901849\n",
      "Epoch 94  Loss: 0.3816841281950474  Accuracy: 82.58949739212898\n",
      "Epoch 95  Loss: 0.37788606626969395  Accuracy: 82.80286865813181\n",
      "Epoch 96  Loss: 0.3783227294457681  Accuracy: 82.6932195353248\n",
      "Epoch 97  Loss: 0.37772525666338025  Accuracy: 82.96882408724514\n",
      "Epoch 98  Loss: 0.374677930704572  Accuracy: 83.12588904694168\n",
      "Epoch 99  Loss: 0.37911252790328226  Accuracy: 82.74359886201991\n",
      "Epoch 100  Loss: 0.3812252819312341  Accuracy: 82.79990516832622\n",
      "Model test accuracy for fold 2: 66.96 \n",
      "Epoch 1  Loss: 3.2876527176210373  Accuracy: 56.848624940730204\n",
      "Epoch 2  Loss: 0.6514651377995809  Accuracy: 61.03010905642485\n",
      "Epoch 3  Loss: 0.6466296396472238  Accuracy: 61.62873399715505\n",
      "Epoch 4  Loss: 0.6429801147544023  Accuracy: 62.28366524419156\n",
      "Epoch 5  Loss: 0.6403059232415576  Accuracy: 62.7993124703651\n",
      "Epoch 6  Loss: 0.632650567275105  Accuracy: 63.55796586059744\n",
      "Epoch 7  Loss: 0.6265049145528765  Accuracy: 64.71965386439071\n",
      "Epoch 8  Loss: 0.6158231634533766  Accuracy: 65.28271692745378\n",
      "Epoch 9  Loss: 0.6076324247952664  Accuracy: 66.27844950213371\n",
      "Epoch 10  Loss: 0.6000903953205455  Accuracy: 66.80891417733523\n",
      "Epoch 11  Loss: 0.5944170071320101  Accuracy: 67.82242769084874\n",
      "Epoch 12  Loss: 0.5881292809816924  Accuracy: 68.13655761024182\n",
      "Epoch 13  Loss: 0.5819670421381792  Accuracy: 68.53662873399716\n",
      "Epoch 14  Loss: 0.5687251103421053  Accuracy: 69.85538169748696\n",
      "Epoch 15  Loss: 0.5692660782599088  Accuracy: 69.79018492176387\n",
      "Epoch 16  Loss: 0.5578963238407265  Accuracy: 70.83333333333333\n",
      "Epoch 17  Loss: 0.5536828357161898  Accuracy: 71.28378378378379\n",
      "Epoch 18  Loss: 0.5494635048689265  Accuracy: 71.64532954006638\n",
      "Epoch 19  Loss: 0.5440645244988528  Accuracy: 71.98909435751541\n",
      "Epoch 20  Loss: 0.5410092423359553  Accuracy: 72.40398293029872\n",
      "Epoch 21  Loss: 0.5335449330282934  Accuracy: 72.64402560455191\n",
      "Epoch 22  Loss: 0.5253176218406721  Accuracy: 73.33155523944998\n",
      "Epoch 23  Loss: 0.5250491431039391  Accuracy: 73.34637268847796\n",
      "Epoch 24  Loss: 0.5209786888550628  Accuracy: 73.57456140350877\n",
      "Epoch 25  Loss: 0.514417904344472  Accuracy: 74.14058795637743\n",
      "Epoch 26  Loss: 0.5132291714350382  Accuracy: 74.22949265054528\n",
      "Epoch 27  Loss: 0.5062596038209669  Accuracy: 74.63549075391181\n",
      "Epoch 28  Loss: 0.5038159279660746  Accuracy: 75.15410146989095\n",
      "Epoch 29  Loss: 0.5028103986247019  Accuracy: 75.02963489805595\n",
      "Epoch 30  Loss: 0.49512285502119496  Accuracy: 75.7290184921764\n",
      "Epoch 31  Loss: 0.49734349503661646  Accuracy: 75.63418681839734\n",
      "Epoch 32  Loss: 0.4927123041089737  Accuracy: 75.65493124703652\n",
      "Epoch 33  Loss: 0.48931120494098373  Accuracy: 76.25059269796112\n",
      "Epoch 34  Loss: 0.4833832804226514  Accuracy: 76.35727833096254\n",
      "Epoch 35  Loss: 0.48111973431977356  Accuracy: 76.27726410621148\n",
      "Epoch 36  Loss: 0.47862901696653076  Accuracy: 76.84032716927453\n",
      "Epoch 37  Loss: 0.4730012401035338  Accuracy: 77.07444286391654\n",
      "Epoch 38  Loss: 0.47621210811264586  Accuracy: 76.59732100521575\n",
      "Epoch 39  Loss: 0.4739706469981959  Accuracy: 76.96183025130394\n",
      "Epoch 40  Loss: 0.4701601799690362  Accuracy: 77.0448079658606\n",
      "Epoch 41  Loss: 0.46730542623183946  Accuracy: 77.21965386439071\n",
      "Epoch 42  Loss: 0.46445005387067795  Accuracy: 77.50711237553342\n",
      "Epoch 43  Loss: 0.45952650182174914  Accuracy: 77.78271692745378\n",
      "Epoch 44  Loss: 0.46145218712362374  Accuracy: 77.92496443812233\n",
      "Epoch 45  Loss: 0.45671660644990025  Accuracy: 78.04646752015174\n",
      "Epoch 46  Loss: 0.45371491823232535  Accuracy: 78.39319582740636\n",
      "Epoch 47  Loss: 0.454560080938267  Accuracy: 78.13537221431959\n",
      "Epoch 48  Loss: 0.4500353636615204  Accuracy: 78.55618776671409\n",
      "Epoch 49  Loss: 0.44092827911178273  Accuracy: 79.00071123755335\n",
      "Epoch 50  Loss: 0.44605670361356303  Accuracy: 78.57693219535325\n",
      "Epoch 51  Loss: 0.4424380696181095  Accuracy: 79.02145566619251\n",
      "Epoch 52  Loss: 0.44190671193328773  Accuracy: 79.0244191559981\n",
      "Epoch 53  Loss: 0.43640552844965097  Accuracy: 79.60526315789474\n",
      "Epoch 54  Loss: 0.435294606807557  Accuracy: 79.33854907539119\n",
      "Epoch 55  Loss: 0.43352281832785317  Accuracy: 79.54302987197724\n",
      "Epoch 56  Loss: 0.4339497896532218  Accuracy: 79.49561403508773\n",
      "Epoch 57  Loss: 0.4367711680630843  Accuracy: 79.33854907539119\n",
      "Epoch 58  Loss: 0.43012871220707893  Accuracy: 79.79788999525842\n",
      "Epoch 59  Loss: 0.42774409744324104  Accuracy: 80.04089615931721\n",
      "Epoch 60  Loss: 0.4213393793413133  Accuracy: 80.36095305832148\n",
      "Epoch 61  Loss: 0.4231986751159032  Accuracy: 80.1090564248459\n",
      "Epoch 62  Loss: 0.4207163610015855  Accuracy: 80.18610715979138\n",
      "Epoch 63  Loss: 0.4204664085850571  Accuracy: 80.32242769084874\n",
      "Epoch 64  Loss: 0.42235078752943966  Accuracy: 80.44393077287815\n",
      "Epoch 65  Loss: 0.419445048961224  Accuracy: 80.39355144618303\n",
      "Epoch 66  Loss: 0.41847371005199174  Accuracy: 80.532835467046\n",
      "Epoch 67  Loss: 0.4163219435422709  Accuracy: 80.61581318160266\n",
      "Epoch 68  Loss: 0.4137298865526011  Accuracy: 80.77287814129919\n",
      "Epoch 69  Loss: 0.41387020367564575  Accuracy: 80.79658605974396\n",
      "Epoch 70  Loss: 0.4110222971349051  Accuracy: 80.7639876718824\n",
      "Epoch 71  Loss: 0.40932582939664525  Accuracy: 81.15220483641536\n",
      "Epoch 72  Loss: 0.40751467927387264  Accuracy: 81.06033665244192\n",
      "Epoch 73  Loss: 0.4065094673723886  Accuracy: 81.15516832622096\n",
      "Epoch 74  Loss: 0.4088180883590019  Accuracy: 81.04551920341395\n",
      "Epoch 75  Loss: 0.40482737891601794  Accuracy: 81.30037932669512\n",
      "Epoch 76  Loss: 0.4012682702053677  Accuracy: 81.48707918444761\n",
      "Epoch 77  Loss: 0.4039031325867682  Accuracy: 81.45448079658605\n",
      "Epoch 78  Loss: 0.3999276674832358  Accuracy: 81.65896159317212\n",
      "Epoch 79  Loss: 0.40154474420529424  Accuracy: 81.72119487908962\n",
      "Epoch 80  Loss: 0.40079935030503705  Accuracy: 81.81899004267426\n",
      "Epoch 81  Loss: 0.39861767795501335  Accuracy: 81.74786628733997\n",
      "Epoch 82  Loss: 0.39768015773910464  Accuracy: 81.80713608345188\n",
      "Epoch 83  Loss: 0.3941704874688929  Accuracy: 81.9701280227596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84  Loss: 0.39443254459536436  Accuracy: 81.94049312470365\n",
      "Epoch 85  Loss: 0.39334077348537516  Accuracy: 81.75379326695116\n",
      "Epoch 86  Loss: 0.3887479229632652  Accuracy: 82.34945471787577\n",
      "Epoch 87  Loss: 0.39067475147771114  Accuracy: 82.05903271692745\n",
      "Epoch 88  Loss: 0.39269690813891817  Accuracy: 82.31389284020862\n",
      "Epoch 89  Loss: 0.39338038015094673  Accuracy: 82.18053579895685\n",
      "Epoch 90  Loss: 0.39400233350919955  Accuracy: 81.80120910384068\n",
      "Epoch 91  Loss: 0.38707614802952967  Accuracy: 82.5154101469891\n",
      "Epoch 92  Loss: 0.383443993600932  Accuracy: 82.6280227596017\n",
      "Epoch 93  Loss: 0.38493003301096684  Accuracy: 82.50355618776672\n",
      "Epoch 94  Loss: 0.38679793527857825  Accuracy: 82.31685633001422\n",
      "Epoch 95  Loss: 0.3819002838184436  Accuracy: 82.59542437174017\n",
      "Epoch 96  Loss: 0.38568777873209026  Accuracy: 82.43243243243244\n",
      "Epoch 97  Loss: 0.3817283412949605  Accuracy: 82.7584163110479\n",
      "Epoch 98  Loss: 0.3813427938995036  Accuracy: 82.76730678046468\n",
      "Epoch 99  Loss: 0.3816577901668621  Accuracy: 82.68136557610242\n",
      "Epoch 100  Loss: 0.3763091398798155  Accuracy: 83.18219535324799\n",
      "Model test accuracy for fold 3: 65.76 \n",
      "Epoch 1  Loss: 1.5385443206989404  Accuracy: 58.07378870943843\n",
      "Epoch 2  Loss: 0.6454221658182867  Accuracy: 61.9202844865906\n",
      "Epoch 3  Loss: 0.6385382962497798  Accuracy: 62.66113498296044\n",
      "Epoch 4  Loss: 0.6305918099753784  Accuracy: 63.63609423618314\n",
      "Epoch 5  Loss: 0.6209851866870215  Accuracy: 64.83923544228774\n",
      "Epoch 6  Loss: 0.6169924056439688  Accuracy: 65.58601274262854\n",
      "Epoch 7  Loss: 0.6050533550706777  Accuracy: 66.45428952437398\n",
      "Epoch 8  Loss: 0.5986431708390062  Accuracy: 66.96695806786191\n",
      "Epoch 9  Loss: 0.5907854601515062  Accuracy: 68.02489257667803\n",
      "Epoch 10  Loss: 0.5833932348724568  Accuracy: 68.54052452215143\n",
      "Epoch 11  Loss: 0.5771005295894363  Accuracy: 69.06801007556675\n",
      "Epoch 12  Loss: 0.5696266461728197  Accuracy: 69.75255593421248\n",
      "Epoch 13  Loss: 0.562582137232477  Accuracy: 70.26226107571492\n",
      "Epoch 14  Loss: 0.5562013437350591  Accuracy: 70.91717291450585\n",
      "Epoch 15  Loss: 0.5508197207342495  Accuracy: 71.43873166395022\n",
      "Epoch 16  Loss: 0.5414986812481375  Accuracy: 71.96029041339457\n",
      "Epoch 17  Loss: 0.5370179037704612  Accuracy: 72.69521410579345\n",
      "Epoch 18  Loss: 0.5320575840093873  Accuracy: 72.96488368647206\n",
      "Epoch 19  Loss: 0.5294911127650377  Accuracy: 73.2315898651652\n",
      "Epoch 20  Loss: 0.5195832726630297  Accuracy: 73.71758779078382\n",
      "Epoch 21  Loss: 0.5179900030295054  Accuracy: 73.85686768410135\n",
      "Epoch 22  Loss: 0.5135133663813273  Accuracy: 74.17395169654763\n",
      "Epoch 23  Loss: 0.5078881054439328  Accuracy: 74.553267150689\n",
      "Epoch 24  Loss: 0.5016468901074294  Accuracy: 75.22003259742183\n",
      "Epoch 25  Loss: 0.4998563619499857  Accuracy: 75.18743517558157\n",
      "Epoch 26  Loss: 0.492907269547383  Accuracy: 75.74751815083717\n",
      "Epoch 27  Loss: 0.4909268310575774  Accuracy: 75.91050526003852\n",
      "Epoch 28  Loss: 0.4869021808333469  Accuracy: 75.9431026818788\n",
      "Epoch 29  Loss: 0.4850127187867959  Accuracy: 76.19202844865906\n",
      "Epoch 30  Loss: 0.47600311650471255  Accuracy: 76.93287894502889\n",
      "Epoch 31  Loss: 0.4774850158754623  Accuracy: 76.98622018076752\n",
      "Epoch 32  Loss: 0.475799852022619  Accuracy: 76.82619647355163\n",
      "Epoch 33  Loss: 0.46831982323166094  Accuracy: 77.65002222551489\n",
      "Epoch 34  Loss: 0.4656056926557512  Accuracy: 77.4751815083716\n",
      "Epoch 35  Loss: 0.4633177044716748  Accuracy: 77.94043562009186\n",
      "Epoch 36  Loss: 0.46078676730394363  Accuracy: 77.65891243147134\n",
      "Epoch 37  Loss: 0.45948739564328483  Accuracy: 77.8189361386872\n",
      "Epoch 38  Loss: 0.45480418679389084  Accuracy: 78.17158097495926\n",
      "Epoch 39  Loss: 0.4534937007860704  Accuracy: 78.50940880130389\n",
      "Epoch 40  Loss: 0.4533640308813615  Accuracy: 78.349385094088\n",
      "Epoch 41  Loss: 0.4496350145023881  Accuracy: 78.47681137946363\n",
      "Epoch 42  Loss: 0.4467372859291958  Accuracy: 78.84427322566306\n",
      "Epoch 43  Loss: 0.44331602210348303  Accuracy: 78.87687064750334\n",
      "Epoch 44  Loss: 0.4395128196161805  Accuracy: 79.24729589568825\n",
      "Epoch 45  Loss: 0.44205712436726596  Accuracy: 79.03096755074826\n",
      "Epoch 46  Loss: 0.4418741236581947  Accuracy: 78.99540672692251\n",
      "Epoch 47  Loss: 0.4382918074049733  Accuracy: 79.03689435471922\n",
      "Epoch 48  Loss: 0.4329193632936839  Accuracy: 79.83404948881316\n",
      "Epoch 49  Loss: 0.4320033226500858  Accuracy: 79.49622166246851\n",
      "Epoch 50  Loss: 0.43180574092901114  Accuracy: 79.75700103719069\n",
      "Epoch 51  Loss: 0.42635925272197434  Accuracy: 79.97925618610165\n",
      "Epoch 52  Loss: 0.4254245022029588  Accuracy: 80.08890205956438\n",
      "Epoch 53  Loss: 0.4226947618704854  Accuracy: 80.14520669728849\n",
      "Epoch 54  Loss: 0.41945485149820644  Accuracy: 80.5897169951104\n",
      "Epoch 55  Loss: 0.4225248076924772  Accuracy: 80.61342421099422\n",
      "Epoch 56  Loss: 0.42056837237694045  Accuracy: 80.5452659653282\n",
      "Epoch 57  Loss: 0.417892106554725  Accuracy: 80.71417987850052\n",
      "Epoch 58  Loss: 0.41897192190993915  Accuracy: 80.46525411172026\n",
      "Epoch 59  Loss: 0.4137541492554275  Accuracy: 80.97199585123722\n",
      "Epoch 60  Loss: 0.41199639665357995  Accuracy: 80.7319602904134\n",
      "Epoch 61  Loss: 0.41471259183052817  Accuracy: 80.8890205956438\n",
      "Epoch 62  Loss: 0.4112617312507196  Accuracy: 80.75863090828271\n",
      "Epoch 63  Loss: 0.4100495535090114  Accuracy: 80.99866646910654\n",
      "Epoch 64  Loss: 0.40785475436485175  Accuracy: 81.39279893317529\n",
      "Epoch 65  Loss: 0.4029807545470469  Accuracy: 81.40168913913172\n",
      "Epoch 66  Loss: 0.41026403484019364  Accuracy: 81.39872573714625\n",
      "Epoch 67  Loss: 0.4054255249599616  Accuracy: 81.37798192324789\n",
      "Epoch 68  Loss: 0.40475392815741623  Accuracy: 81.57356645428952\n",
      "Epoch 69  Loss: 0.4033104825877782  Accuracy: 81.56763965031857\n",
      "Epoch 70  Loss: 0.39986578646031296  Accuracy: 81.60023707215883\n",
      "Epoch 71  Loss: 0.3974257960464015  Accuracy: 81.92324788857609\n",
      "Epoch 72  Loss: 0.39701108340964175  Accuracy: 81.72766335753445\n",
      "Epoch 73  Loss: 0.39717326211658394  Accuracy: 81.792858201215\n",
      "Epoch 74  Loss: 0.39554122270959796  Accuracy: 81.88472366276486\n",
      "Epoch 75  Loss: 0.3948626234901674  Accuracy: 82.09808860571937\n",
      "Epoch 76  Loss: 0.39129462894616707  Accuracy: 82.22255148910949\n",
      "Epoch 77  Loss: 0.39091627796490985  Accuracy: 81.95584531041636\n",
      "Epoch 78  Loss: 0.39117342109481495  Accuracy: 82.2788561268336\n",
      "Epoch 79  Loss: 0.38942089925209683  Accuracy: 82.29959994073197\n",
      "Epoch 80  Loss: 0.3894389552826231  Accuracy: 82.58704993332346\n",
      "Epoch 81  Loss: 0.3854878561740572  Accuracy: 82.57519632538154\n",
      "Epoch 82  Loss: 0.3849904742656332  Accuracy: 82.51296488368648\n",
      "Epoch 83  Loss: 0.38695972220915736  Accuracy: 82.38257519632538\n",
      "Epoch 84  Loss: 0.38868416461980704  Accuracy: 82.45666024596237\n",
      "Epoch 85  Loss: 0.38486093881003786  Accuracy: 82.59594013927989\n",
      "Epoch 86  Loss: 0.386239294527155  Accuracy: 82.39146540228182\n",
      "Epoch 87  Loss: 0.37931184606118634  Accuracy: 82.90117054378426\n",
      "Epoch 88  Loss: 0.38139703982707224  Accuracy: 82.59890354126537\n",
      "Epoch 89  Loss: 0.38313752107999544  Accuracy: 82.49814787375908\n",
      "Epoch 90  Loss: 0.38029864159497345  Accuracy: 82.74411023855386\n",
      "Epoch 91  Loss: 0.38208441278248123  Accuracy: 82.67298859090235\n",
      "Epoch 92  Loss: 0.3831223767589439  Accuracy: 82.57223292339606\n",
      "Epoch 93  Loss: 0.38011977313594386  Accuracy: 82.50111127574455\n",
      "Epoch 94  Loss: 0.37972171435301955  Accuracy: 82.85671951400208\n",
      "Epoch 95  Loss: 0.37858383572011284  Accuracy: 83.00488961327603\n",
      "Epoch 96  Loss: 0.3763844483729565  Accuracy: 83.20343754630315\n",
      "Epoch 97  Loss: 0.37764908164513833  Accuracy: 82.97525559342125\n",
      "Epoch 98  Loss: 0.3713884371699709  Accuracy: 83.27159579196918\n",
      "Epoch 99  Loss: 0.37680530017524055  Accuracy: 82.83597570010372\n",
      "Epoch 100  Loss: 0.374156083460107  Accuracy: 83.08786486886946\n",
      "Higher validaiton accuracy score achieved! Saving model.\n",
      "Model test accuracy for fold 4: 67.16457722059216 \n",
      "Epoch 1  Loss: 52.94250423777284  Accuracy: 46.655800859386574\n",
      "Epoch 2  Loss: 53.372666185552426  Accuracy: 46.63209364350274\n",
      "Epoch 3  Loss: 53.36923196099021  Accuracy: 46.63209364350274\n",
      "Epoch 4  Loss: 53.35721216779767  Accuracy: 46.63209364350274\n",
      "Epoch 5  Loss: 3.754871926975973  Accuracy: 56.59801452066973\n",
      "Epoch 6  Loss: 0.6647409889282603  Accuracy: 59.08727218847237\n",
      "Epoch 7  Loss: 0.6577426197402405  Accuracy: 60.00889020595644\n",
      "Epoch 8  Loss: 0.6516475634592952  Accuracy: 61.00755667506297\n",
      "Epoch 9  Loss: 0.6440897299484774  Accuracy: 62.15439324344347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10  Loss: 0.6325556100769476  Accuracy: 63.3397540376352\n",
      "Epoch 11  Loss: 0.6232631369070574  Accuracy: 64.4006519484368\n",
      "Epoch 12  Loss: 0.6136580195390817  Accuracy: 65.5060008890206\n",
      "Epoch 13  Loss: 0.6063539087772369  Accuracy: 66.24388798340495\n",
      "Epoch 14  Loss: 0.5973704247312113  Accuracy: 67.15068899096163\n",
      "Epoch 15  Loss: 0.5886619820287733  Accuracy: 68.12268484219885\n",
      "Epoch 16  Loss: 0.5820549440880617  Accuracy: 68.8013038968736\n",
      "Epoch 17  Loss: 0.5754690262855906  Accuracy: 68.95836420210402\n",
      "Epoch 18  Loss: 0.5683816354157347  Accuracy: 69.8622018076752\n",
      "Epoch 19  Loss: 0.5627644454891031  Accuracy: 70.47562601866943\n",
      "Epoch 20  Loss: 0.5525666813958775  Accuracy: 71.23129352496666\n",
      "Epoch 21  Loss: 0.5450943447649479  Accuracy: 71.826937324048\n",
      "Epoch 22  Loss: 0.540369269974304  Accuracy: 72.06697288487183\n",
      "Epoch 23  Loss: 0.5331458951713461  Accuracy: 72.6033486442436\n",
      "Epoch 24  Loss: 0.5281519872898405  Accuracy: 73.21973625722329\n",
      "Epoch 25  Loss: 0.5238708859365998  Accuracy: 73.58127129945177\n",
      "Epoch 26  Loss: 0.5195888215393731  Accuracy: 73.63164913320492\n",
      "Epoch 27  Loss: 0.5137902949795579  Accuracy: 74.23618313824271\n",
      "Epoch 28  Loss: 0.510719964675831  Accuracy: 74.15617128463477\n",
      "Epoch 29  Loss: 0.5053192018107935  Accuracy: 74.85849755519337\n",
      "Epoch 30  Loss: 0.4992599454567288  Accuracy: 75.29411764705883\n",
      "Epoch 31  Loss: 0.49581964934865635  Accuracy: 75.46895836420211\n",
      "Epoch 32  Loss: 0.49260343983769417  Accuracy: 75.9431026818788\n",
      "Epoch 33  Loss: 0.488427741057945  Accuracy: 76.13868721292043\n",
      "Epoch 34  Loss: 0.4815571012370514  Accuracy: 76.29871092013632\n",
      "Epoch 35  Loss: 0.4788261480403669  Accuracy: 76.83508667950808\n",
      "Epoch 36  Loss: 0.47532677684317937  Accuracy: 76.90620832715958\n",
      "Epoch 37  Loss: 0.4744384372324655  Accuracy: 76.84990368943548\n",
      "Epoch 38  Loss: 0.46759285044037935  Accuracy: 77.30923099718477\n",
      "Epoch 39  Loss: 0.4660039274304202  Accuracy: 77.5344495480812\n",
      "Epoch 40  Loss: 0.4659831571308049  Accuracy: 77.65594902948585\n",
      "Epoch 41  Loss: 0.46182897528915695  Accuracy: 77.78337531486146\n",
      "Epoch 42  Loss: 0.4603042731230909  Accuracy: 77.76855830493406\n",
      "Epoch 43  Loss: 0.45726358664758276  Accuracy: 77.98488664987406\n",
      "Epoch 44  Loss: 0.45695530871550244  Accuracy: 78.30197066232034\n",
      "Epoch 45  Loss: 0.4510168782012029  Accuracy: 78.62201807675211\n",
      "Epoch 46  Loss: 0.45008554783734406  Accuracy: 78.58645725292637\n",
      "Epoch 47  Loss: 0.4475248240385995  Accuracy: 78.62794488072306\n",
      "Epoch 48  Loss: 0.44417290366960294  Accuracy: 78.93021188324197\n",
      "Epoch 49  Loss: 0.44145147197625856  Accuracy: 79.41620980886057\n",
      "Epoch 50  Loss: 0.43910695826916984  Accuracy: 79.26507630760112\n",
      "Epoch 51  Loss: 0.4375998710818363  Accuracy: 79.14950363016743\n",
      "Epoch 52  Loss: 0.4347511113367297  Accuracy: 79.43695362275892\n",
      "Epoch 53  Loss: 0.43958432690212224  Accuracy: 79.30656393539783\n",
      "Epoch 54  Loss: 0.43112917865316075  Accuracy: 79.71551340939398\n",
      "Epoch 55  Loss: 0.4281148158691146  Accuracy: 80.0296340198548\n",
      "Epoch 56  Loss: 0.43103119832548226  Accuracy: 79.8133056749148\n",
      "Epoch 57  Loss: 0.42562378164042125  Accuracy: 80.02074381389835\n",
      "Epoch 58  Loss: 0.4226071981318069  Accuracy: 80.41487627796711\n",
      "Epoch 59  Loss: 0.42589751461690123  Accuracy: 80.26077937472218\n",
      "Epoch 60  Loss: 0.421733112271988  Accuracy: 80.36153504222848\n",
      "Epoch 61  Loss: 0.42255262985373987  Accuracy: 80.34968143428657\n",
      "Epoch 62  Loss: 0.41795309791059204  Accuracy: 80.63416802489257\n",
      "Epoch 63  Loss: 0.4142680899663405  Accuracy: 80.88013038968737\n",
      "Epoch 64  Loss: 0.4143604610228177  Accuracy: 80.77344791821011\n",
      "Epoch 65  Loss: 0.4150690541348674  Accuracy: 80.61046080900874\n",
      "Epoch 66  Loss: 0.40887743403965776  Accuracy: 80.95421543932434\n",
      "Epoch 67  Loss: 0.41182615235447884  Accuracy: 80.91569121351311\n",
      "Epoch 68  Loss: 0.4087806723334573  Accuracy: 81.25055563787228\n",
      "Epoch 69  Loss: 0.40575586846380524  Accuracy: 81.51726181656542\n",
      "Epoch 70  Loss: 0.40282937195716484  Accuracy: 81.36612831530597\n",
      "Epoch 71  Loss: 0.40746264216123207  Accuracy: 81.04311749888872\n",
      "Epoch 72  Loss: 0.4027079859692039  Accuracy: 81.51429841457994\n",
      "Epoch 73  Loss: 0.3996532600034367  Accuracy: 81.576529856275\n",
      "Epoch 74  Loss: 0.40091947116183513  Accuracy: 81.67728552378131\n",
      "Epoch 75  Loss: 0.397168917863658  Accuracy: 81.86101644688102\n",
      "Epoch 76  Loss: 0.3986197358956843  Accuracy: 81.54393243443474\n",
      "Epoch 77  Loss: 0.39854603181734227  Accuracy: 81.5320788264928\n",
      "Epoch 78  Loss: 0.395557348136649  Accuracy: 82.07141798785005\n",
      "Epoch 79  Loss: 0.3953698384716655  Accuracy: 82.009186546155\n",
      "Epoch 80  Loss: 0.3980429175902497  Accuracy: 81.84027263298266\n",
      "Epoch 81  Loss: 0.39523107106938504  Accuracy: 81.97658912431471\n",
      "Epoch 82  Loss: 0.3930501611621091  Accuracy: 81.99733293821306\n",
      "Epoch 83  Loss: 0.39317443266962515  Accuracy: 82.19291746925471\n",
      "Epoch 84  Loss: 0.39073934710838576  Accuracy: 82.30256334271743\n",
      "Epoch 85  Loss: 0.3896531900108764  Accuracy: 82.1662468513854\n",
      "Epoch 86  Loss: 0.386377628102447  Accuracy: 82.5248184916284\n",
      "Epoch 87  Loss: 0.38530046131574747  Accuracy: 82.63150096310565\n",
      "Epoch 88  Loss: 0.39027315299167775  Accuracy: 82.3381241665432\n",
      "Epoch 89  Loss: 0.38604854250496085  Accuracy: 82.26996592087717\n",
      "Epoch 90  Loss: 0.38618053936145524  Accuracy: 82.2640391169062\n",
      "Epoch 91  Loss: 0.3872160758597381  Accuracy: 82.29663653874648\n",
      "Epoch 92  Loss: 0.38410986880912923  Accuracy: 82.64039116906208\n",
      "Epoch 93  Loss: 0.38334083805481595  Accuracy: 82.64928137501852\n",
      "Epoch 94  Loss: 0.38199330200300075  Accuracy: 82.67595199288783\n",
      "Epoch 95  Loss: 0.38141522895206104  Accuracy: 82.82115869017632\n",
      "Epoch 96  Loss: 0.3779290834385337  Accuracy: 82.87746332790043\n",
      "Epoch 97  Loss: 0.37968320467255334  Accuracy: 82.93673136761002\n",
      "Epoch 98  Loss: 0.3709685858339071  Accuracy: 83.23010816417246\n",
      "Epoch 99  Loss: 0.377514466756221  Accuracy: 82.87449992591495\n",
      "Epoch 100  Loss: 0.3765678958910884  Accuracy: 83.12046229070974\n",
      "Higher validaiton accuracy score achieved! Saving model.\n",
      "Model test accuracy for fold 5: 67.43131501733795 \n",
      "Epoch 1  Loss: 53.15077915336146  Accuracy: 46.63505704548822\n",
      "Epoch 2  Loss: 53.32283336466009  Accuracy: 46.68543487924137\n",
      "Epoch 3  Loss: 53.32283336466009  Accuracy: 46.68543487924137\n",
      "Epoch 4  Loss: 53.30909646641124  Accuracy: 46.68543487924137\n",
      "Epoch 5  Loss: 53.314247810479365  Accuracy: 46.68543487924137\n",
      "Epoch 6  Loss: 53.31768203504158  Accuracy: 46.68543487924137\n",
      "Epoch 7  Loss: 2.9069899876009333  Accuracy: 57.11364646614313\n",
      "Epoch 8  Loss: 0.6594615957953713  Accuracy: 60.26374277670766\n",
      "Epoch 9  Loss: 0.6516363898461516  Accuracy: 60.94236183138243\n",
      "Epoch 10  Loss: 0.6434526567657789  Accuracy: 61.69802933767966\n",
      "Epoch 11  Loss: 0.6364394437634584  Accuracy: 62.48629426581716\n",
      "Epoch 12  Loss: 0.629260597355438  Accuracy: 63.6123870202993\n",
      "Epoch 13  Loss: 0.6189711698980043  Accuracy: 64.6317973033042\n",
      "Epoch 14  Loss: 0.6091628472010294  Accuracy: 65.6037931545414\n",
      "Epoch 15  Loss: 0.6010596939560139  Accuracy: 66.77137353682026\n",
      "Epoch 16  Loss: 0.5935193566661893  Accuracy: 67.2099570306712\n",
      "Epoch 17  Loss: 0.5850315617792534  Accuracy: 68.02192917469254\n",
      "Epoch 18  Loss: 0.5794612218936285  Accuracy: 68.52867091420951\n",
      "Epoch 19  Loss: 0.5715108108565663  Accuracy: 69.21321677285523\n",
      "Epoch 20  Loss: 0.5641685198202278  Accuracy: 69.8770188176026\n",
      "Epoch 21  Loss: 0.5584665346100475  Accuracy: 70.55267447029189\n",
      "Epoch 22  Loss: 0.5520915845126817  Accuracy: 70.9971847681138\n",
      "Epoch 23  Loss: 0.5440966442904689  Accuracy: 71.85064453993184\n",
      "Epoch 24  Loss: 0.5383488030144663  Accuracy: 72.11142391465403\n",
      "Epoch 25  Loss: 0.5343851511451331  Accuracy: 72.64483627204031\n",
      "Epoch 26  Loss: 0.5295204414111195  Accuracy: 73.07156615794932\n",
      "Epoch 27  Loss: 0.5242957398295403  Accuracy: 73.30863831678768\n",
      "Epoch 28  Loss: 0.5198468877510591  Accuracy: 73.64350274114683\n",
      "Epoch 29  Loss: 0.5134259094343041  Accuracy: 73.90428211586902\n",
      "Epoch 30  Loss: 0.5090699470178648  Accuracy: 74.49103570899392\n",
      "Epoch 31  Loss: 0.5091517303477634  Accuracy: 74.63920580826789\n",
      "Epoch 32  Loss: 0.502578373885516  Accuracy: 74.87924136909172\n",
      "Epoch 33  Loss: 0.49790034985000436  Accuracy: 75.45117795228923\n",
      "Epoch 34  Loss: 0.4966318334142367  Accuracy: 75.49859238405689\n",
      "Epoch 35  Loss: 0.4907667263213432  Accuracy: 75.89568825011112\n",
      "Epoch 36  Loss: 0.48893955767606245  Accuracy: 75.93421247592237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37  Loss: 0.48703854914867517  Accuracy: 76.28982071417988\n",
      "Epoch 38  Loss: 0.48175770145925606  Accuracy: 76.51503926507631\n",
      "Epoch 39  Loss: 0.4811611912693038  Accuracy: 76.34612535190399\n",
      "Epoch 40  Loss: 0.47709802797797957  Accuracy: 76.77878204178397\n",
      "Epoch 41  Loss: 0.4763013797275948  Accuracy: 76.82915987553712\n",
      "Epoch 42  Loss: 0.4732457713195772  Accuracy: 76.94176915098534\n",
      "Epoch 43  Loss: 0.46842335096814414  Accuracy: 77.38924285079271\n",
      "Epoch 44  Loss: 0.4668210929993427  Accuracy: 77.49296192028449\n",
      "Epoch 45  Loss: 0.46650426947709284  Accuracy: 77.70336346125352\n",
      "Epoch 46  Loss: 0.46117015702254843  Accuracy: 78.03822788561268\n",
      "Epoch 47  Loss: 0.46260627178531705  Accuracy: 77.68261964735517\n",
      "Epoch 48  Loss: 0.45435556125911797  Accuracy: 78.50348199733294\n",
      "Epoch 49  Loss: 0.4519808345446081  Accuracy: 78.43236034968143\n",
      "Epoch 50  Loss: 0.4556827751750296  Accuracy: 78.07675211142391\n",
      "Epoch 51  Loss: 0.45214815132997255  Accuracy: 78.36716550600089\n",
      "Epoch 52  Loss: 0.4531509712564223  Accuracy: 78.37309230997185\n",
      "Epoch 53  Loss: 0.45244825958754076  Accuracy: 78.21603200474145\n",
      "Epoch 54  Loss: 0.4459697363728827  Accuracy: 78.7375907541858\n",
      "Epoch 55  Loss: 0.44388495656577026  Accuracy: 79.04578456067566\n",
      "Epoch 56  Loss: 0.4484603841873733  Accuracy: 78.61609127278115\n",
      "Epoch 57  Loss: 0.4426825371655551  Accuracy: 79.21173507186249\n",
      "Epoch 58  Loss: 0.44098949579126906  Accuracy: 79.07541858053045\n",
      "Epoch 59  Loss: 0.438413414765488  Accuracy: 79.33619795525263\n",
      "Epoch 60  Loss: 0.4347015001782865  Accuracy: 79.66809897762631\n",
      "Epoch 61  Loss: 0.4344499178908088  Accuracy: 79.641428359757\n",
      "Epoch 62  Loss: 0.43309065891486226  Accuracy: 79.67995258556823\n",
      "Epoch 63  Loss: 0.43132629798668803  Accuracy: 79.83997629278412\n",
      "Epoch 64  Loss: 0.4351187434160348  Accuracy: 79.53474588827974\n",
      "Epoch 65  Loss: 0.4314719441939484  Accuracy: 79.56734331012002\n",
      "Epoch 66  Loss: 0.43005960096012463  Accuracy: 79.70958660542303\n",
      "Epoch 67  Loss: 0.42388206415555696  Accuracy: 80.19262112905615\n",
      "Epoch 68  Loss: 0.4280203835982265  Accuracy: 79.89924433249371\n",
      "Epoch 69  Loss: 0.4260236816198537  Accuracy: 80.45043710179286\n",
      "Epoch 70  Loss: 0.4213410967001409  Accuracy: 80.21632834494\n",
      "Epoch 71  Loss: 0.42000523627255903  Accuracy: 80.59268039709586\n",
      "Epoch 72  Loss: 0.4202556498348713  Accuracy: 80.32301081641725\n",
      "Epoch 73  Loss: 0.42268465538368083  Accuracy: 80.61046080900874\n",
      "Epoch 74  Loss: 0.41660266053495987  Accuracy: 80.46821751370574\n",
      "Epoch 75  Loss: 0.4159410726843458  Accuracy: 80.63120462290709\n",
      "Epoch 76  Loss: 0.4167302331012307  Accuracy: 80.77344791821011\n",
      "Epoch 77  Loss: 0.4131852588192983  Accuracy: 80.91569121351311\n",
      "Epoch 78  Loss: 0.41548060151663696  Accuracy: 80.42672988590903\n",
      "Epoch 79  Loss: 0.4146360157791412  Accuracy: 80.70825307452957\n",
      "Epoch 80  Loss: 0.4123356585023981  Accuracy: 80.92458141946955\n",
      "Epoch 81  Loss: 0.40981868225516693  Accuracy: 81.07275151874352\n",
      "Epoch 82  Loss: 0.41136314652182837  Accuracy: 81.0312638909468\n",
      "Epoch 83  Loss: 0.4079076314740109  Accuracy: 81.20906801007557\n",
      "Epoch 84  Loss: 0.40985151222257904  Accuracy: 81.20610460809009\n",
      "Epoch 85  Loss: 0.4073760308551066  Accuracy: 81.22684842198844\n",
      "Epoch 86  Loss: 0.40317311679775064  Accuracy: 81.15276337235146\n",
      "Epoch 87  Loss: 0.4061639742417769  Accuracy: 81.47577418876871\n",
      "Epoch 88  Loss: 0.404658979877378  Accuracy: 81.25648244184323\n",
      "Epoch 89  Loss: 0.4003727559113141  Accuracy: 81.8224922210698\n",
      "Epoch 90  Loss: 0.40502024814486504  Accuracy: 81.41354274707363\n",
      "Epoch 91  Loss: 0.4000074059674234  Accuracy: 81.65357830789746\n",
      "Epoch 92  Loss: 0.4004476722894293  Accuracy: 81.73062675951994\n",
      "Epoch 93  Loss: 0.3981887461109595  Accuracy: 81.81656541709883\n",
      "Epoch 94  Loss: 0.3970780794819196  Accuracy: 81.81360201511335\n",
      "Epoch 95  Loss: 0.3910293494435874  Accuracy: 82.20773447918211\n",
      "Epoch 96  Loss: 0.3967121647614421  Accuracy: 81.97658912431471\n",
      "Epoch 97  Loss: 0.3947963063238245  Accuracy: 81.9795525263002\n",
      "Epoch 98  Loss: 0.3943995051085949  Accuracy: 81.86694325085197\n",
      "Epoch 99  Loss: 0.3926474879862684  Accuracy: 82.04474736998074\n",
      "Epoch 100  Loss: 0.3912956432411165  Accuracy: 82.03585716402429\n",
      "Model test accuracy for fold 6: 65.53747666044278 \n",
      "Epoch 1  Loss: 0.9226494503743721  Accuracy: 57.88709438435324\n",
      "Epoch 2  Loss: 0.6459995090509906  Accuracy: 61.60023707215884\n",
      "Epoch 3  Loss: 0.6335220815557422  Accuracy: 63.40198547933027\n",
      "Epoch 4  Loss: 0.6276719520489374  Accuracy: 63.7427767076604\n",
      "Epoch 5  Loss: 0.6217368698932908  Accuracy: 64.52215142984146\n",
      "Epoch 6  Loss: 0.6174697957255624  Accuracy: 65.04371017928582\n",
      "Epoch 7  Loss: 0.6147864828958656  Accuracy: 65.24225811231294\n",
      "Epoch 8  Loss: 0.6061866615306247  Accuracy: 66.59356941769151\n",
      "Epoch 9  Loss: 0.6002926061099226  Accuracy: 66.75655652689288\n",
      "Epoch 10  Loss: 0.5946277323545832  Accuracy: 67.5833456808416\n",
      "Epoch 11  Loss: 0.5918103156216217  Accuracy: 67.83523484960735\n",
      "Epoch 12  Loss: 0.5812949826094237  Accuracy: 68.69462142539635\n",
      "Epoch 13  Loss: 0.575191008209279  Accuracy: 69.13616832123277\n",
      "Epoch 14  Loss: 0.5707830548512213  Accuracy: 69.58067861905468\n",
      "Epoch 15  Loss: 0.5635958996911844  Accuracy: 70.034079122833\n",
      "Epoch 16  Loss: 0.5618750942927419  Accuracy: 70.55860127426286\n",
      "Epoch 17  Loss: 0.5542465525143074  Accuracy: 70.97644095421543\n",
      "Epoch 18  Loss: 0.5456396692404242  Accuracy: 71.78841309823677\n",
      "Epoch 19  Loss: 0.5455159634125956  Accuracy: 71.72321825455623\n",
      "Epoch 20  Loss: 0.536680399694226  Accuracy: 72.47592235886798\n",
      "Epoch 21  Loss: 0.5327891198297342  Accuracy: 72.8582012149948\n",
      "Epoch 22  Loss: 0.5289575440639799  Accuracy: 73.07156615794932\n",
      "Epoch 23  Loss: 0.5274165360765024  Accuracy: 73.13972440361535\n",
      "Epoch 24  Loss: 0.519994636602474  Accuracy: 73.74129500666766\n",
      "Epoch 25  Loss: 0.5155139260671355  Accuracy: 74.07023262705586\n",
      "Epoch 26  Loss: 0.5145274623099602  Accuracy: 74.21840272632983\n",
      "Epoch 27  Loss: 0.5090263693621664  Accuracy: 74.39324344347311\n",
      "Epoch 28  Loss: 0.5036304983677287  Accuracy: 74.75477848570158\n",
      "Epoch 29  Loss: 0.499726065293406  Accuracy: 75.04222847829308\n",
      "Epoch 30  Loss: 0.4960535191225283  Accuracy: 75.47784857015854\n",
      "Epoch 31  Loss: 0.4935902842518055  Accuracy: 75.63490887538894\n",
      "Epoch 32  Loss: 0.4930571803089344  Accuracy: 75.7119573270114\n",
      "Epoch 33  Loss: 0.49180123887278815  Accuracy: 75.80382278856126\n",
      "Epoch 34  Loss: 0.48353654033306875  Accuracy: 76.21869906652837\n",
      "Epoch 35  Loss: 0.4796413313033003  Accuracy: 76.56245369684397\n",
      "Epoch 36  Loss: 0.4781970036300746  Accuracy: 76.5861609127278\n",
      "Epoch 37  Loss: 0.47352751017068373  Accuracy: 76.81137946362423\n",
      "Epoch 38  Loss: 0.4738247441974553  Accuracy: 77.01289079863683\n",
      "Epoch 39  Loss: 0.4720933498306708  Accuracy: 76.99511038672397\n",
      "Epoch 40  Loss: 0.4701147964506438  Accuracy: 77.37442584086531\n",
      "Epoch 41  Loss: 0.46387260949069803  Accuracy: 77.47221810638614\n",
      "Epoch 42  Loss: 0.4612450060067755  Accuracy: 77.61446140168914\n",
      "Epoch 43  Loss: 0.460014679779609  Accuracy: 78.064898503482\n",
      "Epoch 44  Loss: 0.45805779934832547  Accuracy: 77.96117943399022\n",
      "Epoch 45  Loss: 0.4563402087625229  Accuracy: 78.06786190546748\n",
      "Epoch 46  Loss: 0.45695588703859935  Accuracy: 78.2219588087124\n",
      "Epoch 47  Loss: 0.45268101730581484  Accuracy: 78.32567787820417\n",
      "Epoch 48  Loss: 0.45125932415777986  Accuracy: 78.35827530004445\n",
      "Epoch 49  Loss: 0.4499725559444139  Accuracy: 78.7375907541858\n",
      "Epoch 50  Loss: 0.44833167924573925  Accuracy: 78.88872425544525\n",
      "Epoch 51  Loss: 0.44457596201788296  Accuracy: 78.87094384353237\n",
      "Epoch 52  Loss: 0.4417828647702029  Accuracy: 79.24136909171729\n",
      "Epoch 53  Loss: 0.4371185919100588  Accuracy: 79.28878352348497\n",
      "Epoch 54  Loss: 0.4379287027951443  Accuracy: 79.2532226996592\n",
      "Epoch 55  Loss: 0.43383870567336225  Accuracy: 79.48733145651208\n",
      "Epoch 56  Loss: 0.4350853476560477  Accuracy: 79.43102681878797\n",
      "Epoch 57  Loss: 0.43509611961516464  Accuracy: 79.4695510445992\n",
      "Epoch 58  Loss: 0.4311654099235029  Accuracy: 79.54067269225071\n",
      "Epoch 59  Loss: 0.42904445799914276  Accuracy: 79.93776855830494\n",
      "Epoch 60  Loss: 0.42610421404242516  Accuracy: 79.89035412653726\n",
      "Epoch 61  Loss: 0.42896043904351466  Accuracy: 79.8281226848422\n",
      "Epoch 62  Loss: 0.42859759610710724  Accuracy: 79.88146392058083\n",
      "Epoch 63  Loss: 0.42166366552313167  Accuracy: 80.27263298266409\n",
      "Epoch 64  Loss: 0.42648149846178113  Accuracy: 79.857756704697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65  Loss: 0.4193974170043613  Accuracy: 80.50970514150245\n",
      "Epoch 66  Loss: 0.42221263242941914  Accuracy: 80.25485257075123\n",
      "Epoch 67  Loss: 0.41814804698030156  Accuracy: 80.56304637724108\n",
      "Epoch 68  Loss: 0.41261147515791835  Accuracy: 80.6875092606312\n",
      "Epoch 69  Loss: 0.4161885351394162  Accuracy: 80.72010668247148\n",
      "Epoch 70  Loss: 0.414469708998998  Accuracy: 80.94828863535338\n",
      "Epoch 71  Loss: 0.4137233869370186  Accuracy: 80.87716698770188\n",
      "Epoch 72  Loss: 0.4131405447242838  Accuracy: 81.18239739220625\n",
      "Epoch 73  Loss: 0.40703792045965337  Accuracy: 81.31575048155283\n",
      "Epoch 74  Loss: 0.4109144066319321  Accuracy: 81.10831234256926\n",
      "Epoch 75  Loss: 0.40592755964308075  Accuracy: 81.19425100014817\n",
      "Epoch 76  Loss: 0.4105875583534891  Accuracy: 80.92754482145503\n",
      "Epoch 77  Loss: 0.40472198921171104  Accuracy: 81.49651800266706\n",
      "Epoch 78  Loss: 0.4052966260774569  Accuracy: 81.434286560972\n",
      "Epoch 79  Loss: 0.40469095381823456  Accuracy: 81.35427470736406\n",
      "Epoch 80  Loss: 0.4002432235036836  Accuracy: 81.61801748407171\n",
      "Epoch 81  Loss: 0.39757771823893895  Accuracy: 81.61209068010075\n",
      "Epoch 82  Loss: 0.3989861588360685  Accuracy: 81.59727367017337\n",
      "Epoch 83  Loss: 0.4019862152636051  Accuracy: 81.48762779671063\n",
      "Epoch 84  Loss: 0.3979466977444562  Accuracy: 81.5913468662024\n",
      "Epoch 85  Loss: 0.3996422745738969  Accuracy: 81.71284634760706\n",
      "Epoch 86  Loss: 0.3983633993475726  Accuracy: 81.5617128463476\n",
      "Epoch 87  Loss: 0.3965399818438472  Accuracy: 81.8906504667358\n",
      "Epoch 88  Loss: 0.3963249537980918  Accuracy: 81.97658912431471\n",
      "Epoch 89  Loss: 0.3961455805057829  Accuracy: 81.75137057341828\n",
      "Epoch 90  Loss: 0.38974953431523207  Accuracy: 82.25514891094977\n",
      "Epoch 91  Loss: 0.3923745719772397  Accuracy: 82.13957623351608\n",
      "Epoch 92  Loss: 0.38884774403590144  Accuracy: 82.18995406726923\n",
      "Epoch 93  Loss: 0.3910291444397334  Accuracy: 81.99140613424211\n",
      "Epoch 94  Loss: 0.3933126466969649  Accuracy: 82.1069788116758\n",
      "Epoch 95  Loss: 0.3911818637315071  Accuracy: 82.07438138983554\n",
      "Epoch 96  Loss: 0.3865024863996289  Accuracy: 82.56926952141058\n",
      "Epoch 97  Loss: 0.3874522570633527  Accuracy: 82.47147725588977\n",
      "Epoch 98  Loss: 0.3863751005494233  Accuracy: 82.22255148910949\n",
      "Epoch 99  Loss: 0.38577375696464017  Accuracy: 82.59594013927989\n",
      "Epoch 100  Loss: 0.3904439949176528  Accuracy: 82.19588087124018\n",
      "Model test accuracy for fold 7: 65.59082421979194 \n",
      "Epoch 1  Loss: 0.8547620299187574  Accuracy: 58.1656541709883\n",
      "Epoch 2  Loss: 0.6478401630213766  Accuracy: 61.34242109942214\n",
      "Epoch 3  Loss: 0.637230312508164  Accuracy: 62.96340198547933\n",
      "Epoch 4  Loss: 0.6346181093743353  Accuracy: 63.21529115424507\n",
      "Epoch 5  Loss: 0.6233282213409742  Accuracy: 64.53696843976886\n",
      "Epoch 6  Loss: 0.6138443055026459  Accuracy: 65.65417098829457\n",
      "Epoch 7  Loss: 0.6092557384434975  Accuracy: 66.26759519928878\n",
      "Epoch 8  Loss: 0.6006078704288511  Accuracy: 66.94621425396355\n",
      "Epoch 9  Loss: 0.5939976525577632  Accuracy: 67.58038227885612\n",
      "Epoch 10  Loss: 0.5832892279281761  Accuracy: 68.55534153207883\n",
      "Epoch 11  Loss: 0.5756260876854261  Accuracy: 69.16580234108757\n",
      "Epoch 12  Loss: 0.5717063491994684  Accuracy: 69.62216624685138\n",
      "Epoch 13  Loss: 0.5650955758085756  Accuracy: 70.51711364646614\n",
      "Epoch 14  Loss: 0.5556382845071229  Accuracy: 71.00903837605571\n",
      "Epoch 15  Loss: 0.5491148123912739  Accuracy: 71.35871981034228\n",
      "Epoch 16  Loss: 0.5450643595646728  Accuracy: 72.00474144317677\n",
      "Epoch 17  Loss: 0.5401353930885141  Accuracy: 72.23588679804415\n",
      "Epoch 18  Loss: 0.5302349920525695  Accuracy: 73.02118832419617\n",
      "Epoch 19  Loss: 0.5230820600056287  Accuracy: 73.63757593717588\n",
      "Epoch 20  Loss: 0.5216355512313771  Accuracy: 73.80945325233368\n",
      "Epoch 21  Loss: 0.5142367488958619  Accuracy: 74.09393984293969\n",
      "Epoch 22  Loss: 0.5130265129334999  Accuracy: 74.1650614905912\n",
      "Epoch 23  Loss: 0.5082555590479663  Accuracy: 74.36953622758928\n",
      "Epoch 24  Loss: 0.4984413007217826  Accuracy: 75.43932434434731\n",
      "Epoch 25  Loss: 0.500602102189353  Accuracy: 75.03037487035117\n",
      "Epoch 26  Loss: 0.49125113518852176  Accuracy: 75.74751815083717\n",
      "Epoch 27  Loss: 0.4906538919065938  Accuracy: 75.61712846347606\n",
      "Epoch 28  Loss: 0.49266796762293036  Accuracy: 75.94606608386428\n",
      "Epoch 29  Loss: 0.48510382877606334  Accuracy: 76.11201659505112\n",
      "Epoch 30  Loss: 0.48153110604846117  Accuracy: 76.63653874648097\n",
      "Epoch 31  Loss: 0.4750111729583957  Accuracy: 77.14328048599792\n",
      "Epoch 32  Loss: 0.47662935360814584  Accuracy: 76.91509853311602\n",
      "Epoch 33  Loss: 0.4710085108650453  Accuracy: 77.10771966217217\n",
      "Epoch 34  Loss: 0.4687433320690285  Accuracy: 77.00103719069492\n",
      "Epoch 35  Loss: 0.46805778710228024  Accuracy: 77.26774336938806\n",
      "Epoch 36  Loss: 0.46165149128346733  Accuracy: 77.79226552081789\n",
      "Epoch 37  Loss: 0.463169209546212  Accuracy: 77.7507778930212\n",
      "Epoch 38  Loss: 0.46286089278080245  Accuracy: 77.98488664987406\n",
      "Epoch 39  Loss: 0.45442807324456447  Accuracy: 78.34642169210254\n",
      "Epoch 40  Loss: 0.4539600331900698  Accuracy: 78.16565417098829\n",
      "Epoch 41  Loss: 0.4550780386409976  Accuracy: 78.19825159282857\n",
      "Epoch 42  Loss: 0.4499884462266257  Accuracy: 78.57164024299897\n",
      "Epoch 43  Loss: 0.44452651702996454  Accuracy: 78.86798044154689\n",
      "Epoch 44  Loss: 0.44623740243189264  Accuracy: 78.63387168469403\n",
      "Epoch 45  Loss: 0.4407189983987447  Accuracy: 79.22951548377537\n",
      "Epoch 46  Loss: 0.43648101513584453  Accuracy: 79.48140465254112\n",
      "Epoch 47  Loss: 0.43773443432468356  Accuracy: 79.39546599496222\n",
      "Epoch 48  Loss: 0.43627711430643545  Accuracy: 79.50511186842495\n",
      "Epoch 49  Loss: 0.43539626783493796  Accuracy: 79.44880723070085\n",
      "Epoch 50  Loss: 0.4337242381139235  Accuracy: 79.43102681878797\n",
      "Epoch 51  Loss: 0.42932210952946637  Accuracy: 79.61475774188769\n",
      "Epoch 52  Loss: 0.4331997925359191  Accuracy: 79.56734331012002\n",
      "Epoch 53  Loss: 0.4269756842969042  Accuracy: 80.07704845162246\n",
      "Epoch 54  Loss: 0.4248996933527065  Accuracy: 79.92887835234849\n",
      "Epoch 55  Loss: 0.42465541884303093  Accuracy: 80.31115720847534\n",
      "Epoch 56  Loss: 0.42500225217504933  Accuracy: 80.04741443176766\n",
      "Epoch 57  Loss: 0.4184411632066423  Accuracy: 80.2311453548674\n",
      "Epoch 58  Loss: 0.42060372775251215  Accuracy: 80.62231441695066\n",
      "Epoch 59  Loss: 0.4204232369860013  Accuracy: 80.23707215883834\n",
      "Epoch 60  Loss: 0.41277056255123834  Accuracy: 80.95125203733886\n",
      "Epoch 61  Loss: 0.41719857016296097  Accuracy: 80.62231441695066\n",
      "Epoch 62  Loss: 0.4087418452131026  Accuracy: 81.08756852867091\n",
      "Epoch 63  Loss: 0.4133051231955037  Accuracy: 80.72307008445695\n",
      "Epoch 64  Loss: 0.41003183072263544  Accuracy: 80.96014224329531\n",
      "Epoch 65  Loss: 0.40854201341668767  Accuracy: 81.04311749888872\n",
      "Epoch 66  Loss: 0.40683653442697093  Accuracy: 81.32760408949474\n",
      "Epoch 67  Loss: 0.41019433409427153  Accuracy: 80.97199585123722\n",
      "Epoch 68  Loss: 0.40612882082209445  Accuracy: 81.360201511335\n",
      "Epoch 69  Loss: 0.4059506563300436  Accuracy: 81.2772262557416\n",
      "Epoch 70  Loss: 0.40378307043151423  Accuracy: 81.44317676692843\n",
      "Epoch 71  Loss: 0.4015279884139697  Accuracy: 81.61505408208623\n",
      "Epoch 72  Loss: 0.4005187079310417  Accuracy: 81.60912727811528\n",
      "Epoch 73  Loss: 0.40242323550311004  Accuracy: 81.45799377685583\n",
      "Epoch 74  Loss: 0.3948086981068958  Accuracy: 82.1069788116758\n",
      "Epoch 75  Loss: 0.3944333859465339  Accuracy: 82.08030819380649\n",
      "Epoch 76  Loss: 0.39615514490640524  Accuracy: 81.8224922210698\n",
      "Epoch 77  Loss: 0.3959142943900643  Accuracy: 81.95288190843088\n",
      "Epoch 78  Loss: 0.39562802276376524  Accuracy: 82.151429841458\n",
      "Epoch 79  Loss: 0.3893287626631332  Accuracy: 82.19588087124018\n",
      "Epoch 80  Loss: 0.3928031623363495  Accuracy: 81.96769891835828\n",
      "Epoch 81  Loss: 0.39297104773647856  Accuracy: 81.96177211438732\n",
      "Epoch 82  Loss: 0.39215955928419577  Accuracy: 82.12772262557417\n",
      "Epoch 83  Loss: 0.3919300932550069  Accuracy: 82.19884427322566\n",
      "Epoch 84  Loss: 0.3875357387869647  Accuracy: 82.30552674470292\n",
      "Epoch 85  Loss: 0.38220628825100983  Accuracy: 82.72336642465551\n",
      "Epoch 86  Loss: 0.3876769302243536  Accuracy: 82.48333086383168\n",
      "Epoch 87  Loss: 0.38350865414196794  Accuracy: 82.55148910949771\n",
      "Epoch 88  Loss: 0.38559311538031604  Accuracy: 82.435916432064\n",
      "Epoch 89  Loss: 0.3822557722415888  Accuracy: 82.67298859090235\n",
      "Epoch 90  Loss: 0.3843784316471129  Accuracy: 82.35886798044154\n",
      "Epoch 91  Loss: 0.37888272157446906  Accuracy: 82.51296488368648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92  Loss: 0.38245852133541397  Accuracy: 82.58408653133797\n",
      "Epoch 93  Loss: 0.38246338814496994  Accuracy: 82.61964735516372\n",
      "Epoch 94  Loss: 0.3797685811578324  Accuracy: 82.84190250407468\n",
      "Epoch 95  Loss: 0.37784873084588483  Accuracy: 83.03156023114535\n",
      "Epoch 96  Loss: 0.380058191716671  Accuracy: 82.77078085642317\n",
      "Epoch 97  Loss: 0.3809714975456397  Accuracy: 82.6818787968588\n",
      "Epoch 98  Loss: 0.378518572923812  Accuracy: 82.91598755371166\n",
      "Epoch 99  Loss: 0.37468784595980786  Accuracy: 82.86560971995851\n",
      "Epoch 100  Loss: 0.3756586770442399  Accuracy: 83.00488961327603\n",
      "Model test accuracy for fold 8: 65.45745532141905 \n",
      "Epoch 1  Loss: 0.8896639213869066  Accuracy: 58.2219588087124\n",
      "Epoch 2  Loss: 0.6459853366920443  Accuracy: 61.77507778930212\n",
      "Epoch 3  Loss: 0.6395487437645594  Accuracy: 62.7678174544377\n",
      "Epoch 4  Loss: 0.6366598369045691  Accuracy: 63.41680248925767\n",
      "Epoch 5  Loss: 0.631266241949616  Accuracy: 63.84056897318121\n",
      "Epoch 6  Loss: 0.6212200135218374  Accuracy: 65.07630760112609\n",
      "Epoch 7  Loss: 0.6110492635405425  Accuracy: 65.70454882204771\n",
      "Epoch 8  Loss: 0.6036508397170992  Accuracy: 66.7239591050526\n",
      "Epoch 9  Loss: 0.5951831842010672  Accuracy: 67.0528967254408\n",
      "Epoch 10  Loss: 0.5887752990379478  Accuracy: 67.87672247740406\n",
      "Epoch 11  Loss: 0.5809556756055716  Accuracy: 68.98503481997334\n",
      "Epoch 12  Loss: 0.5760656420254346  Accuracy: 69.16283893910209\n",
      "Epoch 13  Loss: 0.5728023617782376  Accuracy: 69.49473996147577\n",
      "Epoch 14  Loss: 0.5632048353101268  Accuracy: 70.34819973329382\n",
      "Epoch 15  Loss: 0.5567638292682894  Accuracy: 70.7660394132464\n",
      "Epoch 16  Loss: 0.5518027644491557  Accuracy: 71.27574455474885\n",
      "Epoch 17  Loss: 0.544415746448618  Accuracy: 71.93361979552526\n",
      "Epoch 18  Loss: 0.5380462028763511  Accuracy: 72.22403319010223\n",
      "Epoch 19  Loss: 0.5343563535222502  Accuracy: 72.67743369388057\n",
      "Epoch 20  Loss: 0.5305755024380756  Accuracy: 72.8582012149948\n",
      "Epoch 21  Loss: 0.5233990854837678  Accuracy: 73.58127129945177\n",
      "Epoch 22  Loss: 0.5194286240095441  Accuracy: 73.83316046821751\n",
      "Epoch 23  Loss: 0.5159910094331611  Accuracy: 73.96058675359312\n",
      "Epoch 24  Loss: 0.5073908313431523  Accuracy: 74.65698622018077\n",
      "Epoch 25  Loss: 0.5056755009925726  Accuracy: 74.78144910357089\n",
      "Epoch 26  Loss: 0.504454291228092  Accuracy: 74.70736405393392\n",
      "Epoch 27  Loss: 0.4983142871748317  Accuracy: 75.2407764113202\n",
      "Epoch 28  Loss: 0.4943801093507897  Accuracy: 75.554897021781\n",
      "Epoch 29  Loss: 0.4887977173608361  Accuracy: 76.04385834938509\n",
      "Epoch 30  Loss: 0.48899013391046814  Accuracy: 76.04089494739962\n",
      "Epoch 31  Loss: 0.48591139675541356  Accuracy: 76.12387020299303\n",
      "Epoch 32  Loss: 0.479988738781575  Accuracy: 76.49133204919248\n",
      "Epoch 33  Loss: 0.47811624294880667  Accuracy: 76.6009779226552\n",
      "Epoch 34  Loss: 0.47128989524913556  Accuracy: 77.12253667209957\n",
      "Epoch 35  Loss: 0.4733617146584121  Accuracy: 76.86768410134835\n",
      "Epoch 36  Loss: 0.46811175764058577  Accuracy: 77.3033041932138\n",
      "Epoch 37  Loss: 0.46180645071647386  Accuracy: 77.6915098533116\n",
      "Epoch 38  Loss: 0.4619386193878723  Accuracy: 77.73003407912283\n",
      "Epoch 39  Loss: 0.45717118070884183  Accuracy: 78.13305674914803\n",
      "Epoch 40  Loss: 0.45692960184180376  Accuracy: 78.08564231738035\n",
      "Epoch 41  Loss: 0.45699612367333786  Accuracy: 78.03230108164172\n",
      "Epoch 42  Loss: 0.45445699481801555  Accuracy: 78.0500814935546\n",
      "Epoch 43  Loss: 0.4493163258514621  Accuracy: 78.31382427026226\n",
      "Epoch 44  Loss: 0.4466116271461501  Accuracy: 78.84130982367758\n",
      "Epoch 45  Loss: 0.44476804927443014  Accuracy: 78.92724848125648\n",
      "Epoch 46  Loss: 0.44245791740038176  Accuracy: 79.11986961031263\n",
      "Epoch 47  Loss: 0.44058592651378026  Accuracy: 79.08430878648689\n",
      "Epoch 48  Loss: 0.43685622185920225  Accuracy: 79.41324640687509\n",
      "Epoch 49  Loss: 0.438932513761701  Accuracy: 79.03689435471922\n",
      "Epoch 50  Loss: 0.43243908498323325  Accuracy: 79.76292784116166\n",
      "Epoch 51  Loss: 0.43269079743009625  Accuracy: 79.67995258556823\n",
      "Epoch 52  Loss: 0.4306240857324817  Accuracy: 79.74811083123426\n",
      "Epoch 53  Loss: 0.42758613034631265  Accuracy: 79.97332938213069\n",
      "Epoch 54  Loss: 0.42877188821633655  Accuracy: 79.69773299748111\n",
      "Epoch 55  Loss: 0.42328556943120377  Accuracy: 80.21336494295451\n",
      "Epoch 56  Loss: 0.42456559938463295  Accuracy: 80.19558453104163\n",
      "Epoch 57  Loss: 0.4238957473725984  Accuracy: 80.10668247147726\n",
      "Epoch 58  Loss: 0.4221428403574409  Accuracy: 80.18965772707068\n",
      "Epoch 59  Loss: 0.4148802418600429  Accuracy: 80.84753296784709\n",
      "Epoch 60  Loss: 0.418017357136264  Accuracy: 80.68454585864572\n",
      "Epoch 61  Loss: 0.4218947073501168  Accuracy: 80.43562009186546\n",
      "Epoch 62  Loss: 0.41258927062153816  Accuracy: 81.19721440213365\n",
      "Epoch 63  Loss: 0.4131976931609891  Accuracy: 80.98681286116462\n",
      "Epoch 64  Loss: 0.4087916047058322  Accuracy: 81.0164468810194\n",
      "Epoch 65  Loss: 0.41021921180865983  Accuracy: 80.99866646910654\n",
      "Epoch 66  Loss: 0.40660194612362166  Accuracy: 81.28611646169803\n",
      "Epoch 67  Loss: 0.4080837254948688  Accuracy: 81.06978811675803\n",
      "Epoch 68  Loss: 0.4094912430102175  Accuracy: 80.87716698770188\n",
      "Epoch 69  Loss: 0.40607371000629483  Accuracy: 81.13794636242406\n",
      "Epoch 70  Loss: 0.4070017257648887  Accuracy: 81.08164172469995\n",
      "Epoch 71  Loss: 0.40174202338764164  Accuracy: 81.650614905912\n",
      "Epoch 72  Loss: 0.4004726026094321  Accuracy: 81.7632241813602\n",
      "Epoch 73  Loss: 0.4011759107763117  Accuracy: 81.5617128463476\n",
      "Epoch 74  Loss: 0.39949900645649794  Accuracy: 81.67728552378131\n",
      "Epoch 75  Loss: 0.40139860885612894  Accuracy: 81.29500666765446\n",
      "Epoch 76  Loss: 0.39315785546645976  Accuracy: 82.01511335012594\n",
      "Epoch 77  Loss: 0.3943585087404107  Accuracy: 81.98251592828568\n",
      "Epoch 78  Loss: 0.39709987773588207  Accuracy: 81.88176026077937\n",
      "Epoch 79  Loss: 0.39100568448052264  Accuracy: 82.03289376203882\n",
      "Epoch 80  Loss: 0.39309873059391975  Accuracy: 82.01807675211143\n",
      "Epoch 81  Loss: 0.392733150359356  Accuracy: 82.10401540969032\n",
      "Epoch 82  Loss: 0.3864970570712378  Accuracy: 82.46258704993332\n",
      "Epoch 83  Loss: 0.3850430665029721  Accuracy: 82.39442880426729\n",
      "Epoch 84  Loss: 0.38613383438099513  Accuracy: 82.41220921618017\n",
      "Epoch 85  Loss: 0.3853652023456313  Accuracy: 82.67002518891688\n",
      "Epoch 86  Loss: 0.38685812417304877  Accuracy: 82.07141798785005\n",
      "Epoch 87  Loss: 0.3830197767326326  Accuracy: 82.71743962068454\n",
      "Epoch 88  Loss: 0.3847559650964809  Accuracy: 82.59890354126537\n",
      "Epoch 89  Loss: 0.38742750454129593  Accuracy: 82.50407467773003\n",
      "Epoch 90  Loss: 0.3825987483177221  Accuracy: 82.8833901318714\n",
      "Epoch 91  Loss: 0.3827128813348033  Accuracy: 82.40628241220922\n",
      "Epoch 92  Loss: 0.3831744673238559  Accuracy: 82.6077937472218\n",
      "Epoch 93  Loss: 0.37869587077787425  Accuracy: 82.89524373981331\n",
      "Epoch 94  Loss: 0.38099382129130943  Accuracy: 82.55445251148318\n",
      "Epoch 95  Loss: 0.3792920978457639  Accuracy: 82.7796710623796\n",
      "Epoch 96  Loss: 0.3803211208432913  Accuracy: 82.92191435768262\n",
      "Epoch 97  Loss: 0.3785812057780497  Accuracy: 82.82115869017632\n",
      "Epoch 98  Loss: 0.37669981671779446  Accuracy: 82.89820714179878\n",
      "Epoch 99  Loss: 0.3788144500982581  Accuracy: 82.68484219884428\n",
      "Epoch 100  Loss: 0.37048425649603206  Accuracy: 83.48496073492369\n",
      "Model test accuracy for fold 9: 66.12429981328354 \n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "best_accuracy = 0\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_data)):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      train_data, \n",
    "                      batch_size=128, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      train_data,\n",
    "                      batch_size=32, sampler=test_subsampler)\n",
    "    \n",
    "    model = AccentClassifier().to(device)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = nn.BCELoss()(outputs,labels.to(device).reshape(-1,1))\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            outputs = outputs.reshape(1, -1)\n",
    "            outputs = outputs.squeeze()\n",
    "            for i in range(outputs.size()[0]):\n",
    "                if (labels[i] == 0 and outputs[i] < 0.5) or (labels[i] == 1 and outputs[i] >= 0.5):\n",
    "                    correct += 1\n",
    "\n",
    "       \n",
    "        print(f\"Epoch {epoch + 1}  Loss: {running_loss / len(trainloader)}  Accuracy: {100 * correct / len(train_ids)}\")\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_correct = 0\n",
    "            for j, (d,l) in enumerate(testloader):\n",
    "                o = model(d.to(device))\n",
    "                loss = nn.BCELoss()(o,l.to(device).reshape(-1,1))\n",
    "                test_loss += loss.item()\n",
    "                o = o.reshape(1,-1)\n",
    "                o = o.squeeze()\n",
    "                for i in range(o.size()[0]):\n",
    "                    if (l[i] == 0 and o[i] < 0.5) or (l[i] == 1 and o[i] >= 0.5):\n",
    "                        test_correct += 1\n",
    "\n",
    "            accuracy = 100 * test_correct / len(test_ids)\n",
    "            \n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        print(\"Higher validaiton accuracy score achieved! Saving model.\")\n",
    "        save_model(model)\n",
    "            \n",
    "    \n",
    "            \n",
    "    print(f\"Model test accuracy for fold {fold}: {accuracy} \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.59551760939168\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_data,batch_size=32,shuffle=True)\n",
    "m = AccentClassifier()\n",
    "m.load_state_dict(torch.load(\"binary_accent_classifier.pt\"))\n",
    "m.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    m.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    for j, (d,l) in enumerate(test_loader):\n",
    "        o = m(d.to(device))\n",
    "        loss = nn.BCELoss()(o,l.to(device).reshape(-1,1))\n",
    "        test_loss += loss.item()\n",
    "        o = o.reshape(1,-1)\n",
    "        o = o.squeeze()\n",
    "        for i in range(o.size()[0]):\n",
    "            if (l[i] == 0 and o[i] < 0.5) or (l[i] == 1 and o[i] >= 0.5):\n",
    "                test_correct += 1\n",
    "\n",
    "    accuracy = 100 * test_correct / len(test_data)\n",
    "            \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifying specific set of audio samples\n",
    "def predict(test_dir):\n",
    "    \n",
    "    predictions = dict()\n",
    "    for f in os.listdir(test_dir):\n",
    "        audio_chunks = segment_and_standardize_audio(test_dir / f, 1000)\n",
    "        num_american_pred = 0\n",
    "        for seg in audio_chunks:\n",
    "\n",
    "            samples = seg.get_array_of_samples()\n",
    "            arr = np.array(samples).astype(np.float32)/32768 # 16 bit \n",
    "            arr = librosa.core.resample(arr, seg.frame_rate, 22050, res_type='kaiser_best') \n",
    "\n",
    "            mfcc = librosa.feature.mfcc(y=arr, sr=22050, n_mfcc=50)\n",
    "            data = generate_mfcc_data(mfcc)\n",
    "            pred = model(torch.from_numpy(data).unsqueeze(0).float().to(device)).item()\n",
    "            if pred > 0.5:\n",
    "                num_american_pred += 1\n",
    "        \n",
    "        frac_american_preds = num_american_pred / len(audio_chunks)\n",
    "        \n",
    "        if frac_american_preds >= 0.5:\n",
    "            predictions[f] = 1\n",
    "        else:\n",
    "            predictions[f] = 0\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    x = torch.randn(1, 3, 50, 44, requires_grad=True).to(device)\n",
    "    torch.save(model.state_dict(), \"binary_accent_classifier.pt\")\n",
    "    torch.onnx.export(model, x, \"binary_accent_classifier.onnx\", opset_version=11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_scoring_env",
   "language": "python",
   "name": "accent_scoring_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

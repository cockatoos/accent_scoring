{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, root_dir, train):\n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        \n",
    "        \n",
    "        self.mfccs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(os.listdir(self.root_dir))):\n",
    "\n",
    "            f = os.listdir(self.root_dir)[i]\n",
    "            label = torch.tensor(int(f[0]), dtype=torch.float)\n",
    "            y, sr = librosa.load(self.root_dir / f)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "            data = self.__generate_mfcc_data(mfcc)\n",
    "            self.mfccs.append(torch.from_numpy(data).float())\n",
    "            self.labels.append(label)\n",
    "\n",
    "            if self.train:\n",
    "                noise = np.random.normal(0,1, mfcc.shape)\n",
    "                mfcc_noisy = mfcc + noise\n",
    "                noisy_data = self.__generate_mfcc_data(mfcc_noisy)\n",
    "                self.mfccs.append(torch.from_numpy(noisy_data).float())\n",
    "                self.labels.append(label)\n",
    "\n",
    "            \n",
    "    def __generate_mfcc_data(self, mfcc):\n",
    "        mfcc_standardized = np.zeros(mfcc.shape)\n",
    "        for b in range(mfcc.shape[0]):\n",
    "            mfcc_slice = mfcc[b,:]\n",
    "            centered = mfcc_slice - np.mean(mfcc_slice)\n",
    "            if np.std(centered) != 0:\n",
    "                centered_scaled = centered / np.std(centered)\n",
    "\n",
    "            mfcc_standardized[b,:] = centered_scaled\n",
    "\n",
    "        delta1 = librosa.feature.delta(mfcc_standardized, order=1)\n",
    "        delta2 = librosa.feature.delta(mfcc_standardized, order=2)\n",
    "        mfcc_data = np.stack((mfcc_standardized,delta1,delta2))\n",
    "        \n",
    "        return mfcc_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.mfccs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.mfccs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of english accent files: 579\n",
      "Number of other accent files: 198\n",
      "Number of training files: 300\n",
      "Number of validaiton files: 46\n",
      "Number of test files: 50\n"
     ]
    }
   ],
   "source": [
    "original_dir = Path('C:/Users/omar_/Documents/cockatoos/data/accent_samples/recordings/recordings')\n",
    "train_dir =  Path('C:/Users/omar_/Documents/cockatoos/data/train')\n",
    "val_dir =  Path('C:/Users/omar_/Documents/cockatoos/data/val')\n",
    "test_dir =  Path('C:/Users/omar_/Documents/cockatoos/data/test')\n",
    "\n",
    "files = os.listdir(original_dir)\n",
    "\n",
    "\n",
    "other_accent_types = [\"mandarin\", \"japanese\", \"korean\", \"taiwanese\", \"cantonese\", \"thai\", \"indonesian\"]\n",
    "\n",
    "english_accent_files = []\n",
    "other_accent_files = []\n",
    "\n",
    "num_train_files = 150\n",
    "num_val_files = 23\n",
    "num_test_files = 25\n",
    "\n",
    "end_idx_train = num_train_files\n",
    "end_idx_val = end_idx_train + num_val_files\n",
    "end_idx_test = end_idx_val + num_test_files\n",
    "\n",
    "for f in files:\n",
    "    if \"english\" in f:\n",
    "        english_accent_files.append(f)\n",
    "    \n",
    "    if any(t in f for t in other_accent_types):\n",
    "        other_accent_files.append(f)\n",
    "        \n",
    "np.random.shuffle(english_accent_files)\n",
    "np.random.shuffle(other_accent_files)\n",
    "        \n",
    "print(f\"Number of english accent files: {len(english_accent_files)}\")\n",
    "print(f\"Number of other accent files: {len(other_accent_files)}\")\n",
    "\n",
    "train_files = english_accent_files[0:end_idx_train] + other_accent_files[0:end_idx_train]\n",
    "val_files   = english_accent_files[end_idx_train:end_idx_val] + other_accent_files[end_idx_train:end_idx_val]\n",
    "test_files  = english_accent_files[end_idx_val:end_idx_test] + other_accent_files[end_idx_val:end_idx_test]\n",
    "\n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of validaiton files: {len(val_files)}\")\n",
    "print(f\"Number of test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_data(path, files):\n",
    "    \n",
    "    counter = 0\n",
    "    seg_thresh = 500\n",
    "    \n",
    "    for f in files:\n",
    "        if \"english\" in f:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "            \n",
    "        sound_file = AudioSegment.from_mp3(original_dir / f)\n",
    "        audio_chunks = split_on_silence(sound_file, \n",
    "            # must be silent for at least half a second\n",
    "            min_silence_len = 80,\n",
    "\n",
    "            # consider it silent if quieter than -16 dBFS\n",
    "            silence_thresh=-30\n",
    "        )\n",
    "\n",
    "        \n",
    "        for seg in audio_chunks:\n",
    "            \n",
    "            seg_len = len(seg)\n",
    "    \n",
    "            if seg_len >= seg_thresh:\n",
    "                seg_standardized = seg[0:seg_thresh]\n",
    "            else:\n",
    "                seg_standardized = seg + AudioSegment.silent(duration=(seg_thresh - seg_len))\n",
    "                \n",
    "            out_file = path / f\"{label}_word{counter}.wav\"\n",
    "            counter += 1\n",
    "            seg_standardized.export(out_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training words created\n",
      "Validaiton words created\n",
      "Testing words created\n"
     ]
    }
   ],
   "source": [
    "#Uncomment to create the files for the dataset folders\n",
    "\n",
    "# generate_model_data(train_dir, train_files)\n",
    "# print(\"Training words created\")\n",
    "# generate_model_data(val_dir, val_files)\n",
    "# print(\"Validaiton words created\")\n",
    "# generate_model_data(test_dir, test_files)\n",
    "# print(\"Testing words created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = Path('C:/Users/omar_/Documents/cockatoos/data/train')\n",
    "val_data_dir = Path('C:/Users/omar_/Documents/cockatoos/data/val')\n",
    "test_data_dir = Path('C:/Users/omar_/Documents/cockatoos/data/test')\n",
    "\n",
    "train_data = MFCCDataset(train_data_dir,True)\n",
    "# val_data = MFCCDataset(val_data_dir,False)\n",
    "# test_data = MFCCDataset(test_data_dir,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30346\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model definition\n",
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten(1,3),\n",
    "            nn.Linear(768,128),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Softmax(dim=0)\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.5, inplace=False)\n",
      "  (9): Flatten(start_dim=1, end_dim=3)\n",
      "  (10): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (11): Dropout(p=0.5, inplace=False)\n",
      "  (12): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (13): Softmax(dim=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, avg loss for epoch:1.5608267308663266 \n",
      "Epoch:1, avg loss for epoch:1.5227497042293168 \n",
      "Epoch:2, avg loss for epoch:1.5127733751142238 \n",
      "Epoch:3, avg loss for epoch:1.5045160447395514 \n",
      "Epoch:4, avg loss for epoch:1.4993145132341175 \n",
      "Epoch:5, avg loss for epoch:1.492054014361696 \n",
      "Epoch:6, avg loss for epoch:1.4835579829296397 \n",
      "Epoch:7, avg loss for epoch:1.4785768433039257 \n",
      "Epoch:8, avg loss for epoch:1.471606018043293 \n",
      "Epoch:9, avg loss for epoch:1.4679021722273027 \n",
      "Epoch:10, avg loss for epoch:1.4631020287630807 \n",
      "Epoch:11, avg loss for epoch:1.4579420624844517 \n",
      "Epoch:12, avg loss for epoch:1.4540073163768137 \n",
      "Epoch:13, avg loss for epoch:1.4482370840485657 \n",
      "Epoch:14, avg loss for epoch:1.4448634328279404 \n",
      "Epoch:15, avg loss for epoch:1.4441619467685045 \n",
      "Epoch:16, avg loss for epoch:1.4399929461790715 \n",
      "Epoch:17, avg loss for epoch:1.4359401049302425 \n",
      "Epoch:18, avg loss for epoch:1.4324712093499488 \n",
      "Epoch:19, avg loss for epoch:1.4303337505167728 \n",
      "Epoch:20, avg loss for epoch:1.4269461923831381 \n",
      "Epoch:21, avg loss for epoch:1.4241137011536054 \n",
      "Epoch:22, avg loss for epoch:1.4218733823839556 \n",
      "Epoch:23, avg loss for epoch:1.4192502183331328 \n",
      "Epoch:24, avg loss for epoch:1.4187619291065365 \n",
      "Epoch:25, avg loss for epoch:1.415950843732651 \n",
      "Epoch:26, avg loss for epoch:1.4132793974386502 \n",
      "Epoch:27, avg loss for epoch:1.4101216210203502 \n",
      "Epoch:28, avg loss for epoch:1.4083204263442435 \n",
      "Epoch:29, avg loss for epoch:1.4064804461595255 \n",
      "Epoch:30, avg loss for epoch:1.4043121436498942 \n",
      "Epoch:31, avg loss for epoch:1.4046679622129594 \n",
      "Epoch:32, avg loss for epoch:1.402948744901239 \n",
      "Epoch:33, avg loss for epoch:1.4006983220765663 \n",
      "Epoch:34, avg loss for epoch:1.3970928272532714 \n",
      "Epoch:35, avg loss for epoch:1.3974426597890663 \n",
      "Epoch:36, avg loss for epoch:1.3965373269750396 \n",
      "Epoch:37, avg loss for epoch:1.3958329151691702 \n",
      "Epoch:38, avg loss for epoch:1.393990304748929 \n",
      "Epoch:39, avg loss for epoch:1.3929715652737151 \n",
      "Epoch:40, avg loss for epoch:1.3911784988120435 \n",
      "Epoch:41, avg loss for epoch:1.391027422423609 \n",
      "Epoch:42, avg loss for epoch:1.389596967036405 \n",
      "Epoch:43, avg loss for epoch:1.3876783759877855 \n",
      "Epoch:44, avg loss for epoch:1.3886150023708606 \n",
      "Epoch:45, avg loss for epoch:1.3830205050735755 \n",
      "Epoch:46, avg loss for epoch:1.3857248234547854 \n",
      "Epoch:47, avg loss for epoch:1.3837993482267141 \n",
      "Epoch:48, avg loss for epoch:1.3836007702338056 \n",
      "Epoch:49, avg loss for epoch:1.383011028437519 \n",
      "Epoch:50, avg loss for epoch:1.3817387769043885 \n",
      "Epoch:51, avg loss for epoch:1.3814128529912428 \n",
      "Epoch:52, avg loss for epoch:1.378411083377199 \n",
      "Epoch:53, avg loss for epoch:1.3792443318160994 \n",
      "Epoch:54, avg loss for epoch:1.3789056101136765 \n",
      "Epoch:55, avg loss for epoch:1.3780015559103516 \n",
      "Epoch:56, avg loss for epoch:1.3764847692875515 \n",
      "Epoch:57, avg loss for epoch:1.3745609411009998 \n",
      "Epoch:58, avg loss for epoch:1.3734792235402589 \n",
      "Epoch:59, avg loss for epoch:1.3751480902836621 \n",
      "Epoch:60, avg loss for epoch:1.3729823007473076 \n",
      "Epoch:61, avg loss for epoch:1.3731949921968236 \n",
      "Epoch:62, avg loss for epoch:1.370533797210838 \n",
      "Epoch:63, avg loss for epoch:1.3722379027980647 \n",
      "Epoch:64, avg loss for epoch:1.3690561484486587 \n",
      "Epoch:65, avg loss for epoch:1.3708164633513753 \n",
      "Epoch:66, avg loss for epoch:1.3690939786813534 \n",
      "Epoch:67, avg loss for epoch:1.3695279601627708 \n",
      "Epoch:68, avg loss for epoch:1.3648382983669969 \n",
      "Epoch:69, avg loss for epoch:1.3662838497767333 \n",
      "Epoch:70, avg loss for epoch:1.368740411465487 \n",
      "Epoch:71, avg loss for epoch:1.3651644719413258 \n",
      "Epoch:72, avg loss for epoch:1.3666447407955615 \n",
      "Epoch:73, avg loss for epoch:1.3650160524817487 \n",
      "Epoch:74, avg loss for epoch:1.3632295158062644 \n",
      "Epoch:75, avg loss for epoch:1.3637275641157955 \n",
      "Epoch:76, avg loss for epoch:1.3636173935031992 \n",
      "Epoch:77, avg loss for epoch:1.3629645813566615 \n",
      "Epoch:78, avg loss for epoch:1.3600179142896693 \n",
      "Epoch:79, avg loss for epoch:1.3614151146816378 \n",
      "Epoch:80, avg loss for epoch:1.3614012129502753 \n",
      "Epoch:81, avg loss for epoch:1.3604725900766597 \n",
      "Epoch:82, avg loss for epoch:1.357421457547659 \n",
      "Epoch:83, avg loss for epoch:1.3590853034005401 \n",
      "Epoch:84, avg loss for epoch:1.3592458747335179 \n",
      "Epoch:85, avg loss for epoch:1.3576124939199996 \n",
      "Epoch:86, avg loss for epoch:1.3570276134980115 \n",
      "Epoch:87, avg loss for epoch:1.353994563426057 \n",
      "Epoch:88, avg loss for epoch:1.3540078840827916 \n",
      "Epoch:89, avg loss for epoch:1.3568877438348261 \n",
      "Epoch:90, avg loss for epoch:1.3549823696608287 \n",
      "Epoch:91, avg loss for epoch:1.3531568223106094 \n",
      "Epoch:92, avg loss for epoch:1.3544873949788017 \n",
      "Epoch:93, avg loss for epoch:1.3525162676174598 \n",
      "Epoch:94, avg loss for epoch:1.354393504520739 \n",
      "Epoch:95, avg loss for epoch:1.352104228213665 \n",
      "Epoch:96, avg loss for epoch:1.3548185377527966 \n",
      "Epoch:97, avg loss for epoch:1.3514100902952308 \n",
      "Epoch:98, avg loss for epoch:1.3491130409363825 \n",
      "Epoch:99, avg loss for epoch:1.3521138166476854 \n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = nn.BCELoss()(outputs,labels.to(device).reshape(-1,1))\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    print(f\"Epoch:{epoch}, avg loss for epoch:{running_loss / len(train_loader)} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent_scoring_env",
   "language": "python",
   "name": "accent_scoring_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
